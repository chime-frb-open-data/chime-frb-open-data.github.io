{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to open data releases for the Canadian Hydroden Intensity Mapping Experiment / Fast Radio Bursts . The purposes of this website is to be the central resource for providing access to the data and accompanying code snippets required to get the community started on exploring the CHIME/FRB datasets. Data Releases Tutorials Package Support Note You may use the data presented in this website for publications; however, we ask that you cite the relevant CHIME/FRB Collaboration papers.","title":"Get Started"},{"location":"bandpass.html","text":"PLACEHOLDER (Hi Pranav :)","title":"Applying Bandpass Correction"},{"location":"catalog.html","text":"If you want to take a closer look at the CHIME/FRB Catalog 1 Data, you'll need to know how to read it in. We've made both a CSV and FITS file version of Catalog 1 data available. You'll need the Python packages: numpy and pandas to open the CSV version or just astropy to open the FITS version. See below for sample scripts to open both versions. Example Read in CSV version import numpy as np import pandas as pd # csv file columns (extracted directly from the list that is presented in the Catalog 1 paper) col_list = [ 'tns_name' , 'previous_name' , 'repeater_name' , 'ra' , 'ra_err' , 'ra_notes' , 'dec' , 'dec_err' , 'dec_notes' , 'gl' , 'gb' , 'exp_up' , 'exp_up_err' , 'exp_up_notes' , 'exp_low' , 'exp_low_err' , 'exp_low_notes' , 'bonsai_snr' , 'bonsai_dm' , 'low_ft_68' , 'up_ft_68' , 'low_ft_95' , 'up_ft_95' , 'snr_fitb' , 'dm_fitb' , 'dm_fitb_err' , 'dm_exc_ne2001' , 'dm_exc_ymw16' , 'bc_width' , 'scat_time' , 'scat_time_err' , 'flux' , 'flux_err' , 'flux_notes' , 'fluence' , 'fluence_err' , 'fluence_notes' , 'sub_num' , 'mjd_400' , 'mjd_400_err' , 'mjd_inf' , 'mjd_inf_err' , 'width_fitb' , 'width_fitb_err' , 'sp_idx' , 'sp_idx_err' , 'sp_run' , 'sp_run_err' , 'high_freq' , 'low_freq' , 'peak_freq' , 'excluded_flag' ] # reading in the csv file df = pd . read_csv ( \"catalog1.csv\" , usecols = col_list ) # The Catalog 1 Data now lives in df. You can view they keys for examples with: print ( df . keys ()) Read in FITS version # use the fits file reader in astropy from astropy.io import fits fits_catalog = \"catalog1.fits\" # open the fits file with a context manager, i.e., using with with fits . open ( fits_catalog ) as hdul : # The Catalog 1 Data now lives in hdul. You can view more information about the file with: hdul . info () Tutorial provided by Alice Curtin and Sabrina Berger.","title":"Read in Catalog"},{"location":"code.html","text":"Release 01 | FRBs @ 400MHz \u00b6 For reading msgpack data provided in this release, headover to the CHIME/FRB Open Data Python package. Example Single File from cfod import chime_intensity as ci fn = ` astro_5941664_20180406203904337770_beam0147_00245439_02 . msgpack ` intensity , weights , fpga0 , fpgaN , binning , frame0_nano , nrfifreq , rfi_mask = ci . unpack_data ( fn ) Multiple files from cfod import chime_intensity as ci fns = [ 'file1' , 'file2' , 'file3' ] intensity , weights , fpga0s , fpgaNs , binning , rfi_mask , frame0_nanos = ci . unpack_datafiles ( fns ) Hint where, intensity is a 2D Intensity array. weights are the corresponding 2D array weights to the intensity array. fpga0 (int) is start fpga count of the data chunk. (Internally used to track time, can be ignored). The fpga count increments at the rate of 2.56us. fpgaN (int) is number of fpga counts in the data chunk read binning (int) is the downsampling of the data from the ringbuffer frame0_nano is the conversion from fpga timestamp to utc timestamp (Currently not supported.) nrfifreq is the number of frequences masked by the realtime rfi system (Currently not supported.) rfi_mask is currently not supported Release 03 | Periodic FRB \u00b6 The burst dynamic spectra (waterfalls) for this release constitutes of both intensity and baseband data, stored in npz files. Intensity Data \u00b6 The waterfalls from intensity data have file names burst_*_16k_wfall.npz and are stored at the full resolution of 16,384 frequency channels over 400 MHz with a 0.00098304s time resolution, dedispersed to 348.82 pc cm-3. Baseband Data \u00b6 The waterfalls derived from complex voltage (baseband) data have file names burst_*_bb_1k_wfall.npz and are stored at a resolution of 1,024 frequency channels over 400 MHz with time resolution and dedispersed to the DM as in Extended Data Figure 1 of the paper: {40.96, 40.96, 20.48, 81.92}us and {348.78, 348.82, 348.82, 348.86} pc cm-3. In all cases zapped channels due to RFI are replaced by np.nan . Note that the bursts are too dim too see in individual frequency channels at full resolution. In the paper, we have downsampled the data in frequency for visualization. Data can be accessed and displayed in Python as, e.g.: Example import matplotlib.pyplot as plt import numpy as np fname = \"burst_9_bb_1k_wfall.npz\" data = np . load ( fname ) wfall = data [ \"wfall\" ] dt_s = data [ \"dt_s\" ] center_freq_mhz = data [ \"center_freq_mhz\" ] df_mhz = center_freq_mhz [ 1 ] - center_freq_mhz [ 0 ] plt . imshow ( wfall , origin = \"lower\" , aspect = \"auto\" , interpolation = \"nearest\" , extent = ( 0 , dt_s * wfall . shape [ 1 ], center_freq_mhz [ 0 ] - df_mhz / 2. , center_freq_mhz [ - 1 ] + df_mhz / 2. ) ) plt . xlabel ( \"Time [s]\" ) plt . ylabel ( \"Frequency [MHz]\" ) Release 04 | Galactic Magnetar \u00b6 CHIME/FRB Detection \u00b6 These files for this data release have names chimefrb_SGR1935+2154_20200428_B????.npz where B???? corresponds to the CHIME/FRB beam that recorded that data. The highest S/N detection was made by beam 2067 . The data have a 1024 frequency channels over 400 MHz with time resolution of 0.98304ms and are dedispersed to 332.7206 pc cm-3 . In all cases zapped channels due to RFI are replaced by np.nan . Data can be accessed and displayed in Python as using the following code, Example import glob import matplotlib.pyplot as plt import numpy as np fnames = glob . glob ( \"chimefrb_SGR1935+2154_20200428_B????.npz\" ) for fname in fnames : data = np . load ( fname ) print ( data . files ) intensity = data [ \"intensity\" ] times = data [ \"times\" ] frequencies = data [ \"frequencies\" ] plt . figure () plt . imshow ( intensity , aspect = \"auto\" , origin = \"lower\" , interpolation = \"nearest\" ) plt . show () The NumPy arrays stored in the npz files are: Hint center_frequencies : center frequency of each channel, in MHz center_time : center time of each sample, in s df : channel bandwidth, in MHz dm : dispersion measure, in pc cm-3 dt : sampling time, in s fbottom : frequency at the bottom of the band, in MHz frequencies : lower edge of each channel, in MHz ftop : frequency at the top of the band, in MHz intensity : burst dynamic spectrum nchan : number of channels nsamp : number of samples tend : end of the samples, in s times : left edge of each sample, in s tstart : start of the samples, in s Algonquin Radio Observatory Detection \u00b6 This data has been recorded with the 10-m dish at the Algonquin Radio Observatory and is named, aro_SGR1935+2154_20200428_baseband.npz The NumPy arrays stored in the npz file are: Hint V : coherently dedispersed complex voltages, with shape (nt, nf, npol) start_time : start time of the observation, referenced to 800. MHz end_time : end time of the observation, referenced to 800. MHz DM : dispersion measure, in pc cm-3, to which the data is coherently dedispersed Note that the DM to which the data has been coherently dispersed, 332.80925424 pc cm-3 , is slightly different than the optimal DM measured by CHIME, 332.7206 pc cm-3 . Below is an example of reading in complex voltages, determining Stokes parameters, and plotting the total intensity: Example import matplotlib.pyplot as plt import numpy as np def get_stokes ( data ): X = data [:,:, 0 ] Y = data [:,:, 1 ] I = abs ( X ) ** 2 + abs ( Y ) ** 2 Q = abs ( X ) ** 2 - abs ( Y ) ** 2 U = 2 * np . real ( X * np . conj ( Y )) V = - 2 * np . imag ( X * np . conj ( Y )) return I , Q , U , V data = np . load ( \"aro_SGR1935+2154_20200428_baseband.npz\" ) print ( data . files ) cv = data [ \"V\" ] # complex voltages are shaped (nt, nf, npol) nt , nf , _ = cv . shape tstart = np . datetime64 ( str ( data [ \"start_time\" ])) tstop = np . datetime64 ( str ( data [ \"stop_time\" ])) dt = ( tstop - tstart ) / nt dm = data [ \"DM\" ] freq = np . linspace ( 800 , 400 , 1024 , endpoint = False )[:: - 1 ] I , Q , U , V = get_stokes ( cv ) # change shape to (nf, nt) with the bottom frequency at index 0 intensity = np . flipud ( I . T ) # self-calibrate data for ii in range ( nf ): chan = intensity [ ii ,:] if np . nansum ( chan ) == 0. : continue mean = np . nanmean ( chan ) chan [:] = chan [:] / mean chan [:] = chan [:] - 1 var = np . nanvar ( chan ) chan [:] = chan [:] / var # downsampling factors ds = 384 sub_factor = 4 # downsample if necessary if ds > 1 : new_num_spectra = int ( nt / ds ) num_to_trim = nt % ds if num_to_trim > 0 : intensity = intensity [:,: - num_to_trim ] intensity = np . array ( np . column_stack ( [ np . mean ( intensities , axis = 1 ) for intensities \\ in np . hsplit ( intensity , new_num_spectra )])) nf , nt = intensity . shape # subband if necessary if sub_factor > 1 : intensity = np . nanmean ( intensity . reshape ( - 1 , sub_factor , intensity . shape [ 1 ]), axis = 1 ) freq = np . nanmean ( freq . reshape ( - 1 , sub_factor ), axis = 1 ) time_s = np . arange ( tstart , tstop - dt * ds , dt * ds ) variance = np . nanvar ( intensity , axis = 1 ) # zap outlier channels intensity [ variance > 0.004 , ... ] = 0. # plot waterfall plt . imshow ( intensity , origin = \"lower\" , interpolation = \"nearest\" , aspect = \"auto\" ) plt . savefig ( \"aro_wfall.png\" )","title":"Previous Releases"},{"location":"code.html#release-01-frbs-400mhz","text":"For reading msgpack data provided in this release, headover to the CHIME/FRB Open Data Python package. Example Single File from cfod import chime_intensity as ci fn = ` astro_5941664_20180406203904337770_beam0147_00245439_02 . msgpack ` intensity , weights , fpga0 , fpgaN , binning , frame0_nano , nrfifreq , rfi_mask = ci . unpack_data ( fn ) Multiple files from cfod import chime_intensity as ci fns = [ 'file1' , 'file2' , 'file3' ] intensity , weights , fpga0s , fpgaNs , binning , rfi_mask , frame0_nanos = ci . unpack_datafiles ( fns ) Hint where, intensity is a 2D Intensity array. weights are the corresponding 2D array weights to the intensity array. fpga0 (int) is start fpga count of the data chunk. (Internally used to track time, can be ignored). The fpga count increments at the rate of 2.56us. fpgaN (int) is number of fpga counts in the data chunk read binning (int) is the downsampling of the data from the ringbuffer frame0_nano is the conversion from fpga timestamp to utc timestamp (Currently not supported.) nrfifreq is the number of frequences masked by the realtime rfi system (Currently not supported.) rfi_mask is currently not supported","title":"Release 01 | FRBs @ 400MHz"},{"location":"code.html#release-03-periodic-frb","text":"The burst dynamic spectra (waterfalls) for this release constitutes of both intensity and baseband data, stored in npz files.","title":"Release 03 | Periodic FRB"},{"location":"code.html#intensity-data","text":"The waterfalls from intensity data have file names burst_*_16k_wfall.npz and are stored at the full resolution of 16,384 frequency channels over 400 MHz with a 0.00098304s time resolution, dedispersed to 348.82 pc cm-3.","title":"Intensity Data"},{"location":"code.html#baseband-data","text":"The waterfalls derived from complex voltage (baseband) data have file names burst_*_bb_1k_wfall.npz and are stored at a resolution of 1,024 frequency channels over 400 MHz with time resolution and dedispersed to the DM as in Extended Data Figure 1 of the paper: {40.96, 40.96, 20.48, 81.92}us and {348.78, 348.82, 348.82, 348.86} pc cm-3. In all cases zapped channels due to RFI are replaced by np.nan . Note that the bursts are too dim too see in individual frequency channels at full resolution. In the paper, we have downsampled the data in frequency for visualization. Data can be accessed and displayed in Python as, e.g.: Example import matplotlib.pyplot as plt import numpy as np fname = \"burst_9_bb_1k_wfall.npz\" data = np . load ( fname ) wfall = data [ \"wfall\" ] dt_s = data [ \"dt_s\" ] center_freq_mhz = data [ \"center_freq_mhz\" ] df_mhz = center_freq_mhz [ 1 ] - center_freq_mhz [ 0 ] plt . imshow ( wfall , origin = \"lower\" , aspect = \"auto\" , interpolation = \"nearest\" , extent = ( 0 , dt_s * wfall . shape [ 1 ], center_freq_mhz [ 0 ] - df_mhz / 2. , center_freq_mhz [ - 1 ] + df_mhz / 2. ) ) plt . xlabel ( \"Time [s]\" ) plt . ylabel ( \"Frequency [MHz]\" )","title":"Baseband Data"},{"location":"code.html#release-04-galactic-magnetar","text":"","title":"Release 04 | Galactic Magnetar"},{"location":"code.html#chimefrb-detection","text":"These files for this data release have names chimefrb_SGR1935+2154_20200428_B????.npz where B???? corresponds to the CHIME/FRB beam that recorded that data. The highest S/N detection was made by beam 2067 . The data have a 1024 frequency channels over 400 MHz with time resolution of 0.98304ms and are dedispersed to 332.7206 pc cm-3 . In all cases zapped channels due to RFI are replaced by np.nan . Data can be accessed and displayed in Python as using the following code, Example import glob import matplotlib.pyplot as plt import numpy as np fnames = glob . glob ( \"chimefrb_SGR1935+2154_20200428_B????.npz\" ) for fname in fnames : data = np . load ( fname ) print ( data . files ) intensity = data [ \"intensity\" ] times = data [ \"times\" ] frequencies = data [ \"frequencies\" ] plt . figure () plt . imshow ( intensity , aspect = \"auto\" , origin = \"lower\" , interpolation = \"nearest\" ) plt . show () The NumPy arrays stored in the npz files are: Hint center_frequencies : center frequency of each channel, in MHz center_time : center time of each sample, in s df : channel bandwidth, in MHz dm : dispersion measure, in pc cm-3 dt : sampling time, in s fbottom : frequency at the bottom of the band, in MHz frequencies : lower edge of each channel, in MHz ftop : frequency at the top of the band, in MHz intensity : burst dynamic spectrum nchan : number of channels nsamp : number of samples tend : end of the samples, in s times : left edge of each sample, in s tstart : start of the samples, in s","title":"CHIME/FRB Detection"},{"location":"code.html#algonquin-radio-observatory-detection","text":"This data has been recorded with the 10-m dish at the Algonquin Radio Observatory and is named, aro_SGR1935+2154_20200428_baseband.npz The NumPy arrays stored in the npz file are: Hint V : coherently dedispersed complex voltages, with shape (nt, nf, npol) start_time : start time of the observation, referenced to 800. MHz end_time : end time of the observation, referenced to 800. MHz DM : dispersion measure, in pc cm-3, to which the data is coherently dedispersed Note that the DM to which the data has been coherently dispersed, 332.80925424 pc cm-3 , is slightly different than the optimal DM measured by CHIME, 332.7206 pc cm-3 . Below is an example of reading in complex voltages, determining Stokes parameters, and plotting the total intensity: Example import matplotlib.pyplot as plt import numpy as np def get_stokes ( data ): X = data [:,:, 0 ] Y = data [:,:, 1 ] I = abs ( X ) ** 2 + abs ( Y ) ** 2 Q = abs ( X ) ** 2 - abs ( Y ) ** 2 U = 2 * np . real ( X * np . conj ( Y )) V = - 2 * np . imag ( X * np . conj ( Y )) return I , Q , U , V data = np . load ( \"aro_SGR1935+2154_20200428_baseband.npz\" ) print ( data . files ) cv = data [ \"V\" ] # complex voltages are shaped (nt, nf, npol) nt , nf , _ = cv . shape tstart = np . datetime64 ( str ( data [ \"start_time\" ])) tstop = np . datetime64 ( str ( data [ \"stop_time\" ])) dt = ( tstop - tstart ) / nt dm = data [ \"DM\" ] freq = np . linspace ( 800 , 400 , 1024 , endpoint = False )[:: - 1 ] I , Q , U , V = get_stokes ( cv ) # change shape to (nf, nt) with the bottom frequency at index 0 intensity = np . flipud ( I . T ) # self-calibrate data for ii in range ( nf ): chan = intensity [ ii ,:] if np . nansum ( chan ) == 0. : continue mean = np . nanmean ( chan ) chan [:] = chan [:] / mean chan [:] = chan [:] - 1 var = np . nanvar ( chan ) chan [:] = chan [:] / var # downsampling factors ds = 384 sub_factor = 4 # downsample if necessary if ds > 1 : new_num_spectra = int ( nt / ds ) num_to_trim = nt % ds if num_to_trim > 0 : intensity = intensity [:,: - num_to_trim ] intensity = np . array ( np . column_stack ( [ np . mean ( intensities , axis = 1 ) for intensities \\ in np . hsplit ( intensity , new_num_spectra )])) nf , nt = intensity . shape # subband if necessary if sub_factor > 1 : intensity = np . nanmean ( intensity . reshape ( - 1 , sub_factor , intensity . shape [ 1 ]), axis = 1 ) freq = np . nanmean ( freq . reshape ( - 1 , sub_factor ), axis = 1 ) time_s = np . arange ( tstart , tstop - dt * ds , dt * ds ) variance = np . nanvar ( intensity , axis = 1 ) # zap outlier channels intensity [ variance > 0.004 , ... ] = 0. # plot waterfall plt . imshow ( intensity , origin = \"lower\" , interpolation = \"nearest\" , aspect = \"auto\" ) plt . savefig ( \"aro_wfall.png\" )","title":"Algonquin Radio Observatory Detection"},{"location":"data-formats.html","text":"The CHIME/FRB Experiment either the msgpack data format to store raw channelized intensity data, npz file format for processed intensity or baseband data and the CHIME/Pulsar Experiment uses the filterbank data format. For more information on the instrument parameters refer to The CHIME Fast Radio Burst Project: System Overview . msgpack \u00b6 msgpack data is the beamformed and channelized intensity data which consists of 16384 frequency channels at 1ms cadence. This data is scaled, offset, and packed into 8-bit integers files each consisting of 1.00663296s worth of data. In order to read and uncompress the msgpack data into numpy arrays, checkout the cfod python package. filterbank \u00b6 Filterbank data for the fast radio bursts presented in the data release were analyzed using pubicly availaible packages presto and sigproc . npz \u00b6 A dictionary-like object with lazy-loading of files in the zipped archive, for further reading see official numpy documentation . See the code snippets section for more details on paper specific details.","title":"Formats"},{"location":"data-formats.html#msgpack","text":"msgpack data is the beamformed and channelized intensity data which consists of 16384 frequency channels at 1ms cadence. This data is scaled, offset, and packed into 8-bit integers files each consisting of 1.00663296s worth of data. In order to read and uncompress the msgpack data into numpy arrays, checkout the cfod python package.","title":"msgpack"},{"location":"data-formats.html#filterbank","text":"Filterbank data for the fast radio bursts presented in the data release were analyzed using pubicly availaible packages presto and sigproc .","title":"filterbank"},{"location":"data-formats.html#npz","text":"A dictionary-like object with lazy-loading of files in the zipped archive, for further reading see official numpy documentation . See the code snippets section for more details on paper specific details.","title":"npz"},{"location":"data-releases.html","text":"Release Description Data Release 01 Detection of Fast Radio Bursts at Radio Frequencies Down to 400 MHz link 02 A Second Repeating Fast Radio Burst link 03 Periodic activity from a fast radio burst source link 04 A bright millisecond-duration radio burst from a Galactic magnetar link 05 CHIME/FRB Catalog link","title":"Releases"},{"location":"exposure.html","text":"Below we provide a sample script for creating an exposure map of the Catalog 1 CHIME/FRB Data. This sample script uses the healpy package to project the exposure map onto the 2D plane. You'll need the following Python packages for this example: numpy , matplotlib , healpy , and astropy . The sample script will show you how to create both a high resolution and low resolution exposure map, top and bottom plots respectively. Creating an exposure map for both upper and lower transits import numpy as np import matplotlib.pyplot as plt import healpy as hp from astropy.coordinates import SkyCoord import astropy.units as u fname_u = \"exposure_int_20180828_20191001_transit_U_beam_FWHM-600_res_4s_0.86_arcmin.npz\" fname_l = \"exposure_int_20180828_20191001_transit_L_beam_FWHM-600_res_4s_0.86_arcmin.npz\" with np . load ( fname_u ) as data : exposure = data [ \"exposure\" ] #setting parameters for map resolution # spatial nside = 4096 npix = hp . nside2npix ( nside ) # temporal t_res = 4 # Initializing a healpy map hpxmap = np . zeros ( npix , dtype = np . float ) hpxmap [ 0 : len ( exposure )] += t_res * exposure / ( 3600. ) #seconds to hours hpxmap [ hpxmap == 0 ] = hp . UNSEEN #masking pixels with zero exposure # Plotting hp . mollview ( hpxmap , coord = [ 'C' , 'G' ], norm = 'log' , unit = \"Hours\" ) # Check exposure time in hours for R1 repeater coord = SkyCoord ( \"05:31:58.70\" , \"+33:08:52.5\" , frame = 'icrs' , unit = u . deg ) print ( \"Exposure (in hours): %.2f \" % hpxmap [ hp . ang2pix ( nside , coord . ra . deg , coord . dec . deg , lonlat = True )]) ### Obtaining a lower resolution map ### nside_out = 1024 print ( \"Resolution of new map : %.2f arcmin\" % ( hp . nside2resol ( nside_out , arcmin = True ))) # Degrade healpix resolution to nside_out hpxmap_dg = hp . ud_grade ( hpxmap , nside_out ) hp . mollview ( hpxmap_dg , coord = [ 'C' , 'G' ], norm = 'log' , unit = \"Hours\" ) Hint where, nside_out Varying nside_out parameter below will change the resolution. The nside parameter for the current map is 4096. You can switch to a lower value. However, do not use an nside lower than 512 as you would not be nyquist sampling the CHIME/FRB beam pattern in that case. hpxmap Your HEALpix map will live here. hpxmap_dg Your downgraded HEALpix map will live here. hp.mollview Plots a Mollweide projection of your HEALpix map. Tutorial provided by Dr. Pragya Chawla.","title":"Make an Exposure Map"},{"location":"localization.html","text":"Localizations are key to understanding FRBs and this tutorial will show you how to plot localizations from Catalog 1. You'll need the following Python packages to complete this tutorial: h5py , numpy , healpy , and matplotlib . Loading in localization data \u00b6 The localization data are stored in an HDF5 format. We include various views of the underlying probability distribution, which should be useful for different situations (e.g. healpix maps, contours lists). Example # Load in packages import h5py as h5 import numpy as np import healpy as hp import matplotlib.pyplot as plt # Load in the HDF5 file. f = h5 . File ( 'example.h5' , 'r' ) # The following function just summarizes the HDF5 file structure: def describe ( group , recurse = False ): \"\"\" Prints info on the contents of an hdf5 group \"\"\" print ( group . name ) # First print header-like attributes (if exist) if group . attrs : print ( ' \\n attrs: {' ) for key , value in group . attrs . items (): if key in [ 'comments' , 'history' ]: print ( ' %s :' % key ) for line in value : print ( ' ' + str ( line )) else : print ( ' %s :' % key , value ) if group . attrs : print ( ' }' ) # Then print constituent groups & datasets print () for key , value in group . items (): if isinstance ( value , h5 . Group ): if recurse : print ( '-' * 60 ) describe ( value , True ) else : print ( ' ' + key + '/' ) else : print ( ' ' + key + ':' , value . shape , value . dtype ) print () ROOT \u00b6 The attributes at the root level include some basic parameters: TNS name, the positional values reported in the Catalog table, coordinate system details, and galactic coordinates for convenience. ROOT describe(f['/']) # See hint 1 f['healpix'].attrs['comments'] # See hints below Hint The output from the first line above should be: attrs: { tns_name: FRB20181224D ra: 182.45 ra_hms: 12h09m48s ra_error: 0.197 dec: 54.85 dec_dms: 54d51m00s dec_error: 0.213 glon: 135.42455191200924 glat: 61.256833554798746 frame: ICRS epoch: J2000 units: degrees comments: Reported errors are at the 68% CL. R.A. errors have been scaled by cos(dec). Regions reported here are for the mainlobe island. See further data products for sidelobe islands. } healpix/ projection/ contours/ Hint The output from the second line above should be: array(['Sparse representation of a HEALPix map.', 'ipix := pixel indices (given nside and ordering scheme).', 'CL := confidence level. Any pixel with a CL less than', '0.XX is within the XX% credible region.'], dtype=object) HEALPix \u00b6 A sparse representation of a HEALPix map, where pixels with effectively zero probability have been discarded (typically ~99.99% of the sky). The same resolution is used as the exposure maps (nside = 4096, giving a pixel area of ~0.7 square arcmins). HEALPix describe(f['/healpix']) Hint The output from the line above should be. /healpix attrs: { nside: 4096 ordering: nested comments: Sparse representation of a HEALPix map. ipix := pixel indices (given nside and ordering scheme). CL := confidence level. Any pixel with a CL less than 0.XX is within the XX% credible region. } ipix: (174835,) int64 CL: (174835,) float32 Sampling the Region \u00b6 Example usage of HEALPix nside = f['healpix'].attrs['nside'] ipix, CL = f['healpix/ipix'][()], f['healpix/CL'][()] # example 1: get locations of pixels within 90% confidence bounds # note that initializing the full healpix map is not necessary here ra, dec = hp.pix2ang(nside, ipix[CL < 0.9], nest=True, lonlat=True) # example 2: sampling pixels with weighting sampled = np.random.choice(ipix, 30000, p=(1-CL)/(1-CL).sum()) ra, dec = hp.pix2ang(nside, sampled, nest=True, lonlat=True) PROJECTION \u00b6 A Gnomonic projection of the HEALPix map is included for convenient visualization. This projection method projects from the sphere onto a tangent plane, where the tangent point is centered on the target location. This is an appropriate choice given the ~degree scale of these uncertainty regions. The tangent plane that defines the projection is centered on the highest S/N beam. PROJECTION describe(f['/projection']) Hint /projection attrs: { clon: 182.44863891601562 clon_hms: 12h09m48s clat: 54.858444213867195 clat_dms: 54d51m30s reso: 0.5 xsize: 600 ysize: 120 comments: Gnomonic projection of the HEALPix map, centered around the beam with the highest S/N. Made with healpy.projector.GnomonicProj } data: (120, 600) float32 Making a plot\u00b6 \u00b6 Example hdr = f [ 'projection' ] . attrs CL = f [ 'projection/data' ][:] extent = np . array ([ - hdr [ 'xsize' ] / 2 , hdr [ 'xsize' ] / 2 , - hdr [ 'ysize' ] / 2 , hdr [ 'ysize' ] / 2 ]) * hdr [ 'reso' ] / 60 plt . rc ( 'font' , family = 'serif' , size = 14 ) plt . figure ( figsize = ( 10 , 4 )) # Note: RA increases to the left! im = plt . imshow ( CL , vmin = 0 , origin = 'lower' , extent = extent , cmap = 'magma' ) plt . contour ( CL , levels = [ 0.68 , 0.95 ], linestyles = [ '-' , '--' ], colors = 'k' , linewidths = 2 , extent = extent ) plt . colorbar ( im , pad = 0.25 , shrink = 0.4 , orientation = 'horizontal' , label = 'Confidence Level' ) plt . arrow ( 2.4 , - 0.4 , 0 , 0.2 , head_width = 0.04 , color = 'k' ) plt . text ( 2.39 , - 0.1 , 'N' , ha = 'center' , size = 10 ) plt . arrow ( 2.4 , - 0.4 , - 0.2 , 0. , head_width = 0.04 , color = 'k' ) plt . text ( 2.1 , - 0.4 , 'E' , va = 'center' , ha = 'right' , size = 10 ) plt . title ( 'Centered @ %.3f , %.2f ' % ( hdr [ 'clon' ], hdr [ 'clat' ])) plt . xlabel ( 'dx (deg)' ) plt . ylabel ( 'dy (deg)' ) Your plot generated from the above script should look similar to this plot: Contours \u00b6 Example describe(f['/contours'], recurse=True) Hint The above example's output should look like the following: /contours attrs: { comments: (R.A., Dec.) contours of common confidence intervals. Islands (labelled ABC...) are ordered with increasing R.A. Contours are extracted from the Gnomonic projection, and have been simplified using the Ramer-Douglas-Peucker algorithm (with an epsilon parameter of 0.2 pixels). } ------------------------------------------------------------ /contours/50 A: (2, 22) float32 B: (2, 30) float32 C: (2, 38) float32 ------------------------------------------------------------ /contours/68 A: (2, 24) float32 B: (2, 28) float32 C: (2, 34) float32 D: (2, 43) float32 ------------------------------------------------------------ /contours/90 A: (2, 34) float32 B: (2, 51) float32 C: (2, 46) float32 ------------------------------------------------------------ /contours/95 A: (2, 41) float32 B: (2, 54) float32 C: (2, 48) float32 Making a Contour Plot\u00b6 \u00b6 Example # example 0: getting points ra , dec = f [ 'contours/68/A' ] # example 2: plotting contours plt . figure ( figsize = ( 10 , 2 )) for name , contour in f [ 'contours/68' ] . items (): contour = contour [:] plt . plot ( * contour ) plt . plot ( * contour . mean ( 1 ), 'wo' , mec = 'k' , ms = 20 , alpha = 0.5 ) plt . text ( * contour . mean ( 1 ), s = name , ha = 'center' , va = 'center' ) for contour in f [ 'contours/95' ] . values (): plt . plot ( * contour [:], '--' ) plt . xlim ( * plt . xlim ()[:: - 1 ]) plt . xlabel ( 'R.A. (deg)' ) plt . ylabel ( 'Dec. (deg)' ) Your plot generated from the above script should look similar to this plot: Tutorial provided by Alex Josephy.","title":"Make a Localization Plot"},{"location":"localization.html#loading-in-localization-data","text":"The localization data are stored in an HDF5 format. We include various views of the underlying probability distribution, which should be useful for different situations (e.g. healpix maps, contours lists). Example # Load in packages import h5py as h5 import numpy as np import healpy as hp import matplotlib.pyplot as plt # Load in the HDF5 file. f = h5 . File ( 'example.h5' , 'r' ) # The following function just summarizes the HDF5 file structure: def describe ( group , recurse = False ): \"\"\" Prints info on the contents of an hdf5 group \"\"\" print ( group . name ) # First print header-like attributes (if exist) if group . attrs : print ( ' \\n attrs: {' ) for key , value in group . attrs . items (): if key in [ 'comments' , 'history' ]: print ( ' %s :' % key ) for line in value : print ( ' ' + str ( line )) else : print ( ' %s :' % key , value ) if group . attrs : print ( ' }' ) # Then print constituent groups & datasets print () for key , value in group . items (): if isinstance ( value , h5 . Group ): if recurse : print ( '-' * 60 ) describe ( value , True ) else : print ( ' ' + key + '/' ) else : print ( ' ' + key + ':' , value . shape , value . dtype ) print ()","title":"Loading in localization data"},{"location":"localization.html#root","text":"The attributes at the root level include some basic parameters: TNS name, the positional values reported in the Catalog table, coordinate system details, and galactic coordinates for convenience. ROOT describe(f['/']) # See hint 1 f['healpix'].attrs['comments'] # See hints below Hint The output from the first line above should be: attrs: { tns_name: FRB20181224D ra: 182.45 ra_hms: 12h09m48s ra_error: 0.197 dec: 54.85 dec_dms: 54d51m00s dec_error: 0.213 glon: 135.42455191200924 glat: 61.256833554798746 frame: ICRS epoch: J2000 units: degrees comments: Reported errors are at the 68% CL. R.A. errors have been scaled by cos(dec). Regions reported here are for the mainlobe island. See further data products for sidelobe islands. } healpix/ projection/ contours/ Hint The output from the second line above should be: array(['Sparse representation of a HEALPix map.', 'ipix := pixel indices (given nside and ordering scheme).', 'CL := confidence level. Any pixel with a CL less than', '0.XX is within the XX% credible region.'], dtype=object)","title":"ROOT"},{"location":"localization.html#healpix","text":"A sparse representation of a HEALPix map, where pixels with effectively zero probability have been discarded (typically ~99.99% of the sky). The same resolution is used as the exposure maps (nside = 4096, giving a pixel area of ~0.7 square arcmins). HEALPix describe(f['/healpix']) Hint The output from the line above should be. /healpix attrs: { nside: 4096 ordering: nested comments: Sparse representation of a HEALPix map. ipix := pixel indices (given nside and ordering scheme). CL := confidence level. Any pixel with a CL less than 0.XX is within the XX% credible region. } ipix: (174835,) int64 CL: (174835,) float32","title":"HEALPix"},{"location":"localization.html#sampling-the-region","text":"Example usage of HEALPix nside = f['healpix'].attrs['nside'] ipix, CL = f['healpix/ipix'][()], f['healpix/CL'][()] # example 1: get locations of pixels within 90% confidence bounds # note that initializing the full healpix map is not necessary here ra, dec = hp.pix2ang(nside, ipix[CL < 0.9], nest=True, lonlat=True) # example 2: sampling pixels with weighting sampled = np.random.choice(ipix, 30000, p=(1-CL)/(1-CL).sum()) ra, dec = hp.pix2ang(nside, sampled, nest=True, lonlat=True)","title":"Sampling the Region"},{"location":"localization.html#projection","text":"A Gnomonic projection of the HEALPix map is included for convenient visualization. This projection method projects from the sphere onto a tangent plane, where the tangent point is centered on the target location. This is an appropriate choice given the ~degree scale of these uncertainty regions. The tangent plane that defines the projection is centered on the highest S/N beam. PROJECTION describe(f['/projection']) Hint /projection attrs: { clon: 182.44863891601562 clon_hms: 12h09m48s clat: 54.858444213867195 clat_dms: 54d51m30s reso: 0.5 xsize: 600 ysize: 120 comments: Gnomonic projection of the HEALPix map, centered around the beam with the highest S/N. Made with healpy.projector.GnomonicProj } data: (120, 600) float32","title":"PROJECTION"},{"location":"localization.html#making-a-plot","text":"Example hdr = f [ 'projection' ] . attrs CL = f [ 'projection/data' ][:] extent = np . array ([ - hdr [ 'xsize' ] / 2 , hdr [ 'xsize' ] / 2 , - hdr [ 'ysize' ] / 2 , hdr [ 'ysize' ] / 2 ]) * hdr [ 'reso' ] / 60 plt . rc ( 'font' , family = 'serif' , size = 14 ) plt . figure ( figsize = ( 10 , 4 )) # Note: RA increases to the left! im = plt . imshow ( CL , vmin = 0 , origin = 'lower' , extent = extent , cmap = 'magma' ) plt . contour ( CL , levels = [ 0.68 , 0.95 ], linestyles = [ '-' , '--' ], colors = 'k' , linewidths = 2 , extent = extent ) plt . colorbar ( im , pad = 0.25 , shrink = 0.4 , orientation = 'horizontal' , label = 'Confidence Level' ) plt . arrow ( 2.4 , - 0.4 , 0 , 0.2 , head_width = 0.04 , color = 'k' ) plt . text ( 2.39 , - 0.1 , 'N' , ha = 'center' , size = 10 ) plt . arrow ( 2.4 , - 0.4 , - 0.2 , 0. , head_width = 0.04 , color = 'k' ) plt . text ( 2.1 , - 0.4 , 'E' , va = 'center' , ha = 'right' , size = 10 ) plt . title ( 'Centered @ %.3f , %.2f ' % ( hdr [ 'clon' ], hdr [ 'clat' ])) plt . xlabel ( 'dx (deg)' ) plt . ylabel ( 'dy (deg)' ) Your plot generated from the above script should look similar to this plot:","title":"Making a plot\u00b6"},{"location":"localization.html#contours","text":"Example describe(f['/contours'], recurse=True) Hint The above example's output should look like the following: /contours attrs: { comments: (R.A., Dec.) contours of common confidence intervals. Islands (labelled ABC...) are ordered with increasing R.A. Contours are extracted from the Gnomonic projection, and have been simplified using the Ramer-Douglas-Peucker algorithm (with an epsilon parameter of 0.2 pixels). } ------------------------------------------------------------ /contours/50 A: (2, 22) float32 B: (2, 30) float32 C: (2, 38) float32 ------------------------------------------------------------ /contours/68 A: (2, 24) float32 B: (2, 28) float32 C: (2, 34) float32 D: (2, 43) float32 ------------------------------------------------------------ /contours/90 A: (2, 34) float32 B: (2, 51) float32 C: (2, 46) float32 ------------------------------------------------------------ /contours/95 A: (2, 41) float32 B: (2, 54) float32 C: (2, 48) float32","title":"Contours"},{"location":"localization.html#making-a-contour-plot","text":"Example # example 0: getting points ra , dec = f [ 'contours/68/A' ] # example 2: plotting contours plt . figure ( figsize = ( 10 , 2 )) for name , contour in f [ 'contours/68' ] . items (): contour = contour [:] plt . plot ( * contour ) plt . plot ( * contour . mean ( 1 ), 'wo' , mec = 'k' , ms = 20 , alpha = 0.5 ) plt . text ( * contour . mean ( 1 ), s = name , ha = 'center' , va = 'center' ) for contour in f [ 'contours/95' ] . values (): plt . plot ( * contour [:], '--' ) plt . xlim ( * plt . xlim ()[:: - 1 ]) plt . xlabel ( 'R.A. (deg)' ) plt . ylabel ( 'Dec. (deg)' ) Your plot generated from the above script should look similar to this plot: Tutorial provided by Alex Josephy.","title":"Making a Contour Plot\u00b6"},{"location":"scientific.html","text":"Coming Soon...","title":"Scientific"},{"location":"technical.html","text":"Coming Soon...","title":"Technical"},{"location":"waterfall.html","text":"PLACEHOLDER (Hi Pranav :)","title":"Make a Waterfall Plot"}]}