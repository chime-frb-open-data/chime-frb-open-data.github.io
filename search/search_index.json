{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to open data releases for the Canadian Hydrogen Intensity Mapping Experiment / Fast Radio Bursts . The purpose of this website is to be the central resource for providing access to the data and accompanying code snippets required to get the community started on exploring the CHIME/FRB datasets. Releases Tutorials VOEvents Package Support Note You may use the data presented in this website for publications; however, we ask that you cite the relevant CHIME/FRB Collaboration papers.","title":"Get Started"},{"location":"beam-model/","text":"Authors: Paul Scholz, Marcus Merryfield The beam model used for various analyses in the First CHIME/FRB Catalog is now available to download. The instructions for installation may be found in the CHIME/FRB beam model GitHub repository . This tutorial will guide the user on some useful routines the beam model can perform. Note that this release of the beam model only encompasses the version used for analysis in the First CHIME/FRB Catalog. The CHIME primary beam model is still being improved (see e.g. https://arxiv.org/abs/2201.11822 ), and as such the CHIME/FRB composite beam model (which includes both the CHIME/FRB synthesized FFT beams and the CHIME primary beam) will likely be updated in the future. Coordinate Conventions \u00b6 Before getting started with the CHIME/FRB beam model, it is useful to understand the coordinate convention used: In the grid we use x and y as coordinates which are angles in degrees from the origin. As an origin, (x,y)=(0,0), we use the zenith, which the beam grid is centered on. With zenith as the origin, y is degrees north from zenith and x is degrees west from the meridian (i.e. increasing hour angle). These coordinates were chosen based on how L0 forms beams: The four rows of NS beams will be parallel to meridian The spacings of rows are arbitrary, and we have freedom of where to put them Beams will be spaced in each row as a function of zenith angle, ZA Within each row of 256 beams the spacings are fixed based on the FFT (spaced evenly in sin(ZA) ) Beams IDs are numbered so that the first digit is the S-N running column (i.e 0-3) and the next three digits are the E-W running column. Beam 0001 is the most south-east beam (Beams X000 are used to process the incoherent beam) Beam 0255 is the most north-east beam Beam 3001 is the most south-west beam Beam 3255 is the most north-west beam Diagram of beam labelling. Z denotes the location of zenith in the grid and P denotes the North Celestial Pole. Credit: Mark Halpern The transformation between equatorial coordinates and beam coordinates is shown most clearly when mapping arcs of constant y / Dec map onto equatorial/beam model coordinates, respectively. Arcs of constant y in equatorial coordinates. Each plotted arc corresponds to the center of a beam row that is labelled with its NS index. The horizon is represented by a dashed line. Credit: Paul Scholz Some things to note about the above plot: Since the synthesized beams in the EW direction (where CHIME has only 4 elements forming interferometric baselines) have significant sidelobe structure that is not as suppressed as in the NS direction (where CHIME has 256 elements), these arcs are a representation of the strip of the sky a given beam row is sensitive to. The arcs of constant y arc downwards in declination as one moves away from the meridian. That means that the sidelobes of beams are always sensitive to sources at lower declination than their nominal positions. Arcs of constant declination in beam grid coordinates. Each arc corresponds to a declination shown in the legend. Tick marks on the arcs represent the distance a source travels in an hour. The location of beam rows are shown on the meridian as their NS indexes. The horizon is represented by a dashed line. Credit: Paul Scholz Some things to note about the above plot: At high declinations, sources spend a lot of time within the beam grid, (and thus the main lobe of the telescope primary beam) and so we have a large amount of exposure time near the North Celestial Pole (NCP). Near the NCP, RA changes very rapidly for small separations on the sky. For example, at decl. = 85\u25e6 (\u223cbeam row 214), beam columns 0 and 3 are separated by 15\u25e6 (1 hour) in RA. Sources on the sky that are detected outside of the beam grid will always appear at y\u2019s higher than during their transits. This can be seen in Figure 2 where the declination arcs turn upwards. This means that sidelobe detections will occur at higher beam rows than at transit and their localizations will assign a higher declination than the actual source. Generating beam model sensitivities \u00b6 When generating sensitivities from the CHIME/FRB beam model, there are three important inputs to get_sensitivity . The first is the length N array of beam numbers for which you want to calculate sensitivities. The second is the (M,2) array of beam model (x,y) coordinate positions for which you want to calculate sensitivities. The last is the length K array of frequencies for which to calculate sensitivities. The returned array of sensitivities has shape (M,N,K) . In the following example, we'll calculate sensitivities for a single beam, at one coordinate position, and for all 16384 CHIME/FRB frequencies. Note that some frequencies in the beam model cannot be appropriately modeled due to interference. This normally isn't an issue, since the missing frequencies are also masked in detected FRBs. However, in cases where you wish to interpolate through these otherwise missing \"bad frequencies\", the interpolate_bad_freq option is available. Hint: to get the most accurate CHIME/FRB-specific values, use the chime-frb-constants package, installable via pip install chime-frb-constants . Beam coordinates import numpy as np import chime_frb_constants import cfbm # First create a beam model object of the CHIME/FRB composite beam model bm = cfbm . CompositeBeamModel ( interpolate_bad_freq = False ) # First choose a beam number (here we'll use only one) beam_no = [ 1064 ] # Next choose a position in the beam. We'll use the center of our chosen beam # at 600 MHz (note the beam shape & size change as a function of frequency) pos = bm . get_beam_positions ( beam_no , freqs = [ 600 ]) # In this example, squeeze the unused array dimensions, as get_beam_positions # returns an NxMx2 array where N is the length of the beam number array and M # is the length of the frequencies array pos = np . squeeze ( pos ) # The last ingredient is a list of frequencies: we'll get beam sensitivities # for all 16k frequencies in chime_frb_constants freqs = chime_frb_constants . FREQ # Finally, calculate the sensitivities sensitivities = bm . get_sensitivity ( beam_no , pos , freqs ) # Once again, in this example we'll squeeze unused array dimensions sensitivities = np . squeeze ( sensitivities ) # Now we have our array of sensitivities representing the beam sensitivity in # beam 1064, at 16384 frequencies from 400 to 800 MHz, and at the position of the # 600 MHz beam center! Oftentimes you may want to calculate sensitivities like in the above example, but for (RA, Dec) pairs instead of beam model coordinate pairs. Fortunately there are functions in cfbm to convert between beam model coordinates and sky coordinates given a datetime. cfbm.get_equatorial_from_position converts beam position to equatorial coordinates given a time, and cfbm.get_position_from_equatorial does the reverse. Sky coordinates from datetime import datetime import numpy as np import chime_frb_constants import cfbm # Create a beam model, choose a beam number, and generate the frequencies as before bm = cfbm . CompositeBeamModel ( interpolate_bad_freq = False ) beam_no = [ 1064 ] freqs = chime_frb_constants . FREQ # Setting the RA and Dec coordinates, choosing a time, and getting the corresponding # x and y coordinates ra = 370.7 dec = 24.0 t = datetime ( year = 2022 , month = 1 , day = 1 ) x , y = cfbm . get_position_from_equatorial ( ra , dec , t ) pos = np . array ([ x , y ]) # Finally, get the beam sensitivities with the (x,y) position and squeeze # unused dimensions sensitivities = bm . get_sensitivity ( beam_no , pos , freqs ) sensitivities = np . squeeze ( sensitivities ) A plot of the sensitivities generated in the first example. Credit: Marcus Merryfield The output sensitivities from the beam model range from 0 to slightly above 1. The value can be interpreted as the relative sensitivity compared to the center of the CHIME primary beam.","title":"Use the CHIME/FRB Beam Model"},{"location":"beam-model/#coordinate-conventions","text":"Before getting started with the CHIME/FRB beam model, it is useful to understand the coordinate convention used: In the grid we use x and y as coordinates which are angles in degrees from the origin. As an origin, (x,y)=(0,0), we use the zenith, which the beam grid is centered on. With zenith as the origin, y is degrees north from zenith and x is degrees west from the meridian (i.e. increasing hour angle). These coordinates were chosen based on how L0 forms beams: The four rows of NS beams will be parallel to meridian The spacings of rows are arbitrary, and we have freedom of where to put them Beams will be spaced in each row as a function of zenith angle, ZA Within each row of 256 beams the spacings are fixed based on the FFT (spaced evenly in sin(ZA) ) Beams IDs are numbered so that the first digit is the S-N running column (i.e 0-3) and the next three digits are the E-W running column. Beam 0001 is the most south-east beam (Beams X000 are used to process the incoherent beam) Beam 0255 is the most north-east beam Beam 3001 is the most south-west beam Beam 3255 is the most north-west beam Diagram of beam labelling. Z denotes the location of zenith in the grid and P denotes the North Celestial Pole. Credit: Mark Halpern The transformation between equatorial coordinates and beam coordinates is shown most clearly when mapping arcs of constant y / Dec map onto equatorial/beam model coordinates, respectively. Arcs of constant y in equatorial coordinates. Each plotted arc corresponds to the center of a beam row that is labelled with its NS index. The horizon is represented by a dashed line. Credit: Paul Scholz Some things to note about the above plot: Since the synthesized beams in the EW direction (where CHIME has only 4 elements forming interferometric baselines) have significant sidelobe structure that is not as suppressed as in the NS direction (where CHIME has 256 elements), these arcs are a representation of the strip of the sky a given beam row is sensitive to. The arcs of constant y arc downwards in declination as one moves away from the meridian. That means that the sidelobes of beams are always sensitive to sources at lower declination than their nominal positions. Arcs of constant declination in beam grid coordinates. Each arc corresponds to a declination shown in the legend. Tick marks on the arcs represent the distance a source travels in an hour. The location of beam rows are shown on the meridian as their NS indexes. The horizon is represented by a dashed line. Credit: Paul Scholz Some things to note about the above plot: At high declinations, sources spend a lot of time within the beam grid, (and thus the main lobe of the telescope primary beam) and so we have a large amount of exposure time near the North Celestial Pole (NCP). Near the NCP, RA changes very rapidly for small separations on the sky. For example, at decl. = 85\u25e6 (\u223cbeam row 214), beam columns 0 and 3 are separated by 15\u25e6 (1 hour) in RA. Sources on the sky that are detected outside of the beam grid will always appear at y\u2019s higher than during their transits. This can be seen in Figure 2 where the declination arcs turn upwards. This means that sidelobe detections will occur at higher beam rows than at transit and their localizations will assign a higher declination than the actual source.","title":"Coordinate Conventions"},{"location":"beam-model/#generating-beam-model-sensitivities","text":"When generating sensitivities from the CHIME/FRB beam model, there are three important inputs to get_sensitivity . The first is the length N array of beam numbers for which you want to calculate sensitivities. The second is the (M,2) array of beam model (x,y) coordinate positions for which you want to calculate sensitivities. The last is the length K array of frequencies for which to calculate sensitivities. The returned array of sensitivities has shape (M,N,K) . In the following example, we'll calculate sensitivities for a single beam, at one coordinate position, and for all 16384 CHIME/FRB frequencies. Note that some frequencies in the beam model cannot be appropriately modeled due to interference. This normally isn't an issue, since the missing frequencies are also masked in detected FRBs. However, in cases where you wish to interpolate through these otherwise missing \"bad frequencies\", the interpolate_bad_freq option is available. Hint: to get the most accurate CHIME/FRB-specific values, use the chime-frb-constants package, installable via pip install chime-frb-constants . Beam coordinates import numpy as np import chime_frb_constants import cfbm # First create a beam model object of the CHIME/FRB composite beam model bm = cfbm . CompositeBeamModel ( interpolate_bad_freq = False ) # First choose a beam number (here we'll use only one) beam_no = [ 1064 ] # Next choose a position in the beam. We'll use the center of our chosen beam # at 600 MHz (note the beam shape & size change as a function of frequency) pos = bm . get_beam_positions ( beam_no , freqs = [ 600 ]) # In this example, squeeze the unused array dimensions, as get_beam_positions # returns an NxMx2 array where N is the length of the beam number array and M # is the length of the frequencies array pos = np . squeeze ( pos ) # The last ingredient is a list of frequencies: we'll get beam sensitivities # for all 16k frequencies in chime_frb_constants freqs = chime_frb_constants . FREQ # Finally, calculate the sensitivities sensitivities = bm . get_sensitivity ( beam_no , pos , freqs ) # Once again, in this example we'll squeeze unused array dimensions sensitivities = np . squeeze ( sensitivities ) # Now we have our array of sensitivities representing the beam sensitivity in # beam 1064, at 16384 frequencies from 400 to 800 MHz, and at the position of the # 600 MHz beam center! Oftentimes you may want to calculate sensitivities like in the above example, but for (RA, Dec) pairs instead of beam model coordinate pairs. Fortunately there are functions in cfbm to convert between beam model coordinates and sky coordinates given a datetime. cfbm.get_equatorial_from_position converts beam position to equatorial coordinates given a time, and cfbm.get_position_from_equatorial does the reverse. Sky coordinates from datetime import datetime import numpy as np import chime_frb_constants import cfbm # Create a beam model, choose a beam number, and generate the frequencies as before bm = cfbm . CompositeBeamModel ( interpolate_bad_freq = False ) beam_no = [ 1064 ] freqs = chime_frb_constants . FREQ # Setting the RA and Dec coordinates, choosing a time, and getting the corresponding # x and y coordinates ra = 370.7 dec = 24.0 t = datetime ( year = 2022 , month = 1 , day = 1 ) x , y = cfbm . get_position_from_equatorial ( ra , dec , t ) pos = np . array ([ x , y ]) # Finally, get the beam sensitivities with the (x,y) position and squeeze # unused dimensions sensitivities = bm . get_sensitivity ( beam_no , pos , freqs ) sensitivities = np . squeeze ( sensitivities ) A plot of the sensitivities generated in the first example. Credit: Marcus Merryfield The output sensitivities from the beam model range from 0 to slightly above 1. The value can be interpreted as the relative sensitivity compared to the center of the CHIME primary beam.","title":"Generating beam model sensitivities"},{"location":"catalog/","text":"Authors: Alice Curtin, Sabrina Berger In order to take a closer look at the CHIME/FRB Catalog Data download it from our official website which is updated regularly. The catalog data is available in CSV and FITS file formats. Read in CHIME/FRB Catalog Pandas Dataframe import numpy as np import pandas as pd # csv file columns (extracted directly from the list that is presented in the Catalog 1 paper) col_list = [ 'tns_name' , 'previous_name' , 'repeater_name' , 'ra' , 'ra_err' , 'ra_notes' , 'dec' , 'dec_err' , 'dec_notes' , 'gl' , 'gb' , 'exp_up' , 'exp_up_err' , 'exp_up_notes' , 'exp_low' , 'exp_low_err' , 'exp_low_notes' , 'bonsai_snr' , 'bonsai_dm' , 'low_ft_68' , 'up_ft_68' , 'low_ft_95' , 'up_ft_95' , 'snr_fitb' , 'dm_fitb' , 'dm_fitb_err' , 'dm_exc_ne2001' , 'dm_exc_ymw16' , 'bc_width' , 'scat_time' , 'scat_time_err' , 'flux' , 'flux_err' , 'flux_notes' , 'fluence' , 'fluence_err' , 'fluence_notes' , 'sub_num' , 'mjd_400' , 'mjd_400_err' , 'mjd_inf' , 'mjd_inf_err' , 'width_fitb' , 'width_fitb_err' , 'sp_idx' , 'sp_idx_err' , 'sp_run' , 'sp_run_err' , 'high_freq' , 'low_freq' , 'peak_freq' , 'excluded_flag' ] # reading in the csv file df = pd . read_csv ( \"catalog1.csv\" , usecols = col_list ) # The Catalog 1 Data now lives in df. You can view they keys for examples with: print ( df . keys ()) FITS # use the fits file reader in astropy from astropy.io import fits fits_catalog = \"catalog1.fits\" # open the fits file with a context manager, i.e., using with with fits . open ( fits_catalog ) as hdul : # The Catalog 1 Data now lives in hdul. You can view more information about the file with: hdul . info () In addition to downloading the catalog manually, it is also availaible through the open source CHIME/FRB Open Data python package. cfod Dictionary from cfod import catalog data = catalog . as_dict () JSON from cfod import catalog data = catalog . as_json () List from cfod import catalog data = catalog . as_list () Dataframe from cfod import catalog data = catalog . as_dataframe () FITS from cfod import catalog data = catalog . as_dataframe ()","title":"Read the Catalog"},{"location":"code/","text":"Release 01 | FRBs @ 400MHz \u00b6 For reading msgpack data provided in this release, headover to the CHIME/FRB Open Data Python package. Example Single File from cfod.analysis.intensity import chime_intensity as ci fn = ` astro_5941664_20180406203904337770_beam0147_00245439_02 . msgpack ` intensity , weights , fpga0 , fpgaN , binning , frame0_nano , nrfifreq , rfi_mask = ci . unpack_data ( fn ) Multiple files from cfod.analysis.intensity import chime_intensity as ci fns = [ 'file1' , 'file2' , 'file3' ] intensity , weights , fpga0s , fpgaNs , binning , rfi_mask , frame0_nanos = ci . unpack_datafiles ( fns ) Hint where, intensity is a 2D Intensity array. weights are the corresponding 2D array weights to the intensity array. fpga0 (int) is start fpga count of the data chunk. (Internally used to track time, can be ignored). The fpga count increments at the rate of 2.56us. fpgaN (int) is number of fpga counts in the data chunk read binning (int) is the downsampling of the data from the ringbuffer frame0_nano is the conversion from fpga timestamp to utc timestamp (Currently not supported.) nrfifreq is the number of frequences masked by the realtime rfi system (Currently not supported.) rfi_mask is currently not supported Release 03 | Periodic FRB \u00b6 The burst dynamic spectra (waterfalls) for this release constitutes of both intensity and baseband data, stored in npz files. Intensity Data \u00b6 The waterfalls from intensity data have file names burst_*_16k_wfall.npz and are stored at the full resolution of 16,384 frequency channels over 400 MHz with a 0.00098304s time resolution, dedispersed to 348.82 pc cm-3. Baseband Data \u00b6 The waterfalls derived from complex voltage (baseband) data have file names burst_*_bb_1k_wfall.npz and are stored at a resolution of 1,024 frequency channels over 400 MHz with time resolution and dedispersed to the DM as in Extended Data Figure 1 of the paper: {40.96, 40.96, 20.48, 81.92}us and {348.78, 348.82, 348.82, 348.86} pc cm-3. In all cases zapped channels due to RFI are replaced by np.nan . Note that the bursts are too dim too see in individual frequency channels at full resolution. In the paper, we have downsampled the data in frequency for visualization. Data can be accessed and displayed in Python as, e.g.: Example import matplotlib.pyplot as plt import numpy as np fname = \"burst_9_bb_1k_wfall.npz\" data = np . load ( fname ) wfall = data [ \"wfall\" ] dt_s = data [ \"dt_s\" ] center_freq_mhz = data [ \"center_freq_mhz\" ] df_mhz = center_freq_mhz [ 1 ] - center_freq_mhz [ 0 ] plt . imshow ( wfall , origin = \"lower\" , aspect = \"auto\" , interpolation = \"nearest\" , extent = ( 0 , dt_s * wfall . shape [ 1 ], center_freq_mhz [ 0 ] - df_mhz / 2. , center_freq_mhz [ - 1 ] + df_mhz / 2. ) ) plt . xlabel ( \"Time [s]\" ) plt . ylabel ( \"Frequency [MHz]\" ) Release 04 | Galactic Magnetar \u00b6 CHIME/FRB Detection \u00b6 These files for this data release have names chimefrb_SGR1935+2154_20200428_B????.npz where B???? corresponds to the CHIME/FRB beam that recorded that data. The highest S/N detection was made by beam 2067 . The data have a 1024 frequency channels over 400 MHz with time resolution of 0.98304ms and are dedispersed to 332.7206 pc cm-3 . In all cases zapped channels due to RFI are replaced by np.nan . Data can be accessed and displayed in Python as using the following code, Example import glob import matplotlib.pyplot as plt import numpy as np fnames = glob . glob ( \"chimefrb_SGR1935+2154_20200428_B????.npz\" ) for fname in fnames : data = np . load ( fname ) print ( data . files ) intensity = data [ \"intensity\" ] times = data [ \"times\" ] frequencies = data [ \"frequencies\" ] plt . figure () plt . imshow ( intensity , aspect = \"auto\" , origin = \"lower\" , interpolation = \"nearest\" ) plt . show () The NumPy arrays stored in the npz files are: Hint center_frequencies : center frequency of each channel, in MHz center_time : center time of each sample, in s df : channel bandwidth, in MHz dm : dispersion measure, in pc cm-3 dt : sampling time, in s fbottom : frequency at the bottom of the band, in MHz frequencies : lower edge of each channel, in MHz ftop : frequency at the top of the band, in MHz intensity : burst dynamic spectrum nchan : number of channels nsamp : number of samples tend : end of the samples, in s times : left edge of each sample, in s tstart : start of the samples, in s Algonquin Radio Observatory Detection \u00b6 This data has been recorded with the 10-m dish at the Algonquin Radio Observatory and is named, aro_SGR1935+2154_20200428_baseband.npz The NumPy arrays stored in the npz file are: Hint V : coherently dedispersed complex voltages, with shape (nt, nf, npol) start_time : start time of the observation, referenced to 800. MHz end_time : end time of the observation, referenced to 800. MHz DM : dispersion measure, in pc cm-3, to which the data is coherently dedispersed Note that the DM to which the data has been coherently dispersed, 332.80925424 pc cm-3 , is slightly different than the optimal DM measured by CHIME, 332.7206 pc cm-3 . Below is an example of reading in complex voltages, determining Stokes parameters, and plotting the total intensity: Example import matplotlib.pyplot as plt import numpy as np def get_stokes ( data ): X = data [:,:, 0 ] Y = data [:,:, 1 ] I = abs ( X ) ** 2 + abs ( Y ) ** 2 Q = abs ( X ) ** 2 - abs ( Y ) ** 2 U = 2 * np . real ( X * np . conj ( Y )) V = - 2 * np . imag ( X * np . conj ( Y )) return I , Q , U , V data = np . load ( \"aro_SGR1935+2154_20200428_baseband.npz\" ) print ( data . files ) cv = data [ \"V\" ] # complex voltages are shaped (nt, nf, npol) nt , nf , _ = cv . shape tstart = np . datetime64 ( str ( data [ \"start_time\" ])) tstop = np . datetime64 ( str ( data [ \"stop_time\" ])) dt = ( tstop - tstart ) / nt dm = data [ \"DM\" ] freq = np . linspace ( 800 , 400 , 1024 , endpoint = False )[:: - 1 ] I , Q , U , V = get_stokes ( cv ) # change shape to (nf, nt) with the bottom frequency at index 0 intensity = np . flipud ( I . T ) # self-calibrate data for ii in range ( nf ): chan = intensity [ ii ,:] if np . nansum ( chan ) == 0. : continue mean = np . nanmean ( chan ) chan [:] = chan [:] / mean chan [:] = chan [:] - 1 var = np . nanvar ( chan ) chan [:] = chan [:] / var # downsampling factors ds = 384 sub_factor = 4 # downsample if necessary if ds > 1 : new_num_spectra = int ( nt / ds ) num_to_trim = nt % ds if num_to_trim > 0 : intensity = intensity [:,: - num_to_trim ] intensity = np . array ( np . column_stack ( [ np . mean ( intensities , axis = 1 ) for intensities \\ in np . hsplit ( intensity , new_num_spectra )])) nf , nt = intensity . shape # subband if necessary if sub_factor > 1 : intensity = np . nanmean ( intensity . reshape ( - 1 , sub_factor , intensity . shape [ 1 ]), axis = 1 ) freq = np . nanmean ( freq . reshape ( - 1 , sub_factor ), axis = 1 ) time_s = np . arange ( tstart , tstop - dt * ds , dt * ds ) variance = np . nanvar ( intensity , axis = 1 ) # zap outlier channels intensity [ variance > 0.004 , ... ] = 0. # plot waterfall plt . imshow ( intensity , origin = \"lower\" , interpolation = \"nearest\" , aspect = \"auto\" ) plt . savefig ( \"aro_wfall.png\" )","title":"Previous Releases"},{"location":"code/#release-01-frbs-400mhz","text":"For reading msgpack data provided in this release, headover to the CHIME/FRB Open Data Python package. Example Single File from cfod.analysis.intensity import chime_intensity as ci fn = ` astro_5941664_20180406203904337770_beam0147_00245439_02 . msgpack ` intensity , weights , fpga0 , fpgaN , binning , frame0_nano , nrfifreq , rfi_mask = ci . unpack_data ( fn ) Multiple files from cfod.analysis.intensity import chime_intensity as ci fns = [ 'file1' , 'file2' , 'file3' ] intensity , weights , fpga0s , fpgaNs , binning , rfi_mask , frame0_nanos = ci . unpack_datafiles ( fns ) Hint where, intensity is a 2D Intensity array. weights are the corresponding 2D array weights to the intensity array. fpga0 (int) is start fpga count of the data chunk. (Internally used to track time, can be ignored). The fpga count increments at the rate of 2.56us. fpgaN (int) is number of fpga counts in the data chunk read binning (int) is the downsampling of the data from the ringbuffer frame0_nano is the conversion from fpga timestamp to utc timestamp (Currently not supported.) nrfifreq is the number of frequences masked by the realtime rfi system (Currently not supported.) rfi_mask is currently not supported","title":"Release 01 | FRBs @ 400MHz"},{"location":"code/#release-03-periodic-frb","text":"The burst dynamic spectra (waterfalls) for this release constitutes of both intensity and baseband data, stored in npz files.","title":"Release 03 | Periodic FRB"},{"location":"code/#intensity-data","text":"The waterfalls from intensity data have file names burst_*_16k_wfall.npz and are stored at the full resolution of 16,384 frequency channels over 400 MHz with a 0.00098304s time resolution, dedispersed to 348.82 pc cm-3.","title":"Intensity Data"},{"location":"code/#baseband-data","text":"The waterfalls derived from complex voltage (baseband) data have file names burst_*_bb_1k_wfall.npz and are stored at a resolution of 1,024 frequency channels over 400 MHz with time resolution and dedispersed to the DM as in Extended Data Figure 1 of the paper: {40.96, 40.96, 20.48, 81.92}us and {348.78, 348.82, 348.82, 348.86} pc cm-3. In all cases zapped channels due to RFI are replaced by np.nan . Note that the bursts are too dim too see in individual frequency channels at full resolution. In the paper, we have downsampled the data in frequency for visualization. Data can be accessed and displayed in Python as, e.g.: Example import matplotlib.pyplot as plt import numpy as np fname = \"burst_9_bb_1k_wfall.npz\" data = np . load ( fname ) wfall = data [ \"wfall\" ] dt_s = data [ \"dt_s\" ] center_freq_mhz = data [ \"center_freq_mhz\" ] df_mhz = center_freq_mhz [ 1 ] - center_freq_mhz [ 0 ] plt . imshow ( wfall , origin = \"lower\" , aspect = \"auto\" , interpolation = \"nearest\" , extent = ( 0 , dt_s * wfall . shape [ 1 ], center_freq_mhz [ 0 ] - df_mhz / 2. , center_freq_mhz [ - 1 ] + df_mhz / 2. ) ) plt . xlabel ( \"Time [s]\" ) plt . ylabel ( \"Frequency [MHz]\" )","title":"Baseband Data"},{"location":"code/#release-04-galactic-magnetar","text":"","title":"Release 04 | Galactic Magnetar"},{"location":"code/#chimefrb-detection","text":"These files for this data release have names chimefrb_SGR1935+2154_20200428_B????.npz where B???? corresponds to the CHIME/FRB beam that recorded that data. The highest S/N detection was made by beam 2067 . The data have a 1024 frequency channels over 400 MHz with time resolution of 0.98304ms and are dedispersed to 332.7206 pc cm-3 . In all cases zapped channels due to RFI are replaced by np.nan . Data can be accessed and displayed in Python as using the following code, Example import glob import matplotlib.pyplot as plt import numpy as np fnames = glob . glob ( \"chimefrb_SGR1935+2154_20200428_B????.npz\" ) for fname in fnames : data = np . load ( fname ) print ( data . files ) intensity = data [ \"intensity\" ] times = data [ \"times\" ] frequencies = data [ \"frequencies\" ] plt . figure () plt . imshow ( intensity , aspect = \"auto\" , origin = \"lower\" , interpolation = \"nearest\" ) plt . show () The NumPy arrays stored in the npz files are: Hint center_frequencies : center frequency of each channel, in MHz center_time : center time of each sample, in s df : channel bandwidth, in MHz dm : dispersion measure, in pc cm-3 dt : sampling time, in s fbottom : frequency at the bottom of the band, in MHz frequencies : lower edge of each channel, in MHz ftop : frequency at the top of the band, in MHz intensity : burst dynamic spectrum nchan : number of channels nsamp : number of samples tend : end of the samples, in s times : left edge of each sample, in s tstart : start of the samples, in s","title":"CHIME/FRB Detection"},{"location":"code/#algonquin-radio-observatory-detection","text":"This data has been recorded with the 10-m dish at the Algonquin Radio Observatory and is named, aro_SGR1935+2154_20200428_baseband.npz The NumPy arrays stored in the npz file are: Hint V : coherently dedispersed complex voltages, with shape (nt, nf, npol) start_time : start time of the observation, referenced to 800. MHz end_time : end time of the observation, referenced to 800. MHz DM : dispersion measure, in pc cm-3, to which the data is coherently dedispersed Note that the DM to which the data has been coherently dispersed, 332.80925424 pc cm-3 , is slightly different than the optimal DM measured by CHIME, 332.7206 pc cm-3 . Below is an example of reading in complex voltages, determining Stokes parameters, and plotting the total intensity: Example import matplotlib.pyplot as plt import numpy as np def get_stokes ( data ): X = data [:,:, 0 ] Y = data [:,:, 1 ] I = abs ( X ) ** 2 + abs ( Y ) ** 2 Q = abs ( X ) ** 2 - abs ( Y ) ** 2 U = 2 * np . real ( X * np . conj ( Y )) V = - 2 * np . imag ( X * np . conj ( Y )) return I , Q , U , V data = np . load ( \"aro_SGR1935+2154_20200428_baseband.npz\" ) print ( data . files ) cv = data [ \"V\" ] # complex voltages are shaped (nt, nf, npol) nt , nf , _ = cv . shape tstart = np . datetime64 ( str ( data [ \"start_time\" ])) tstop = np . datetime64 ( str ( data [ \"stop_time\" ])) dt = ( tstop - tstart ) / nt dm = data [ \"DM\" ] freq = np . linspace ( 800 , 400 , 1024 , endpoint = False )[:: - 1 ] I , Q , U , V = get_stokes ( cv ) # change shape to (nf, nt) with the bottom frequency at index 0 intensity = np . flipud ( I . T ) # self-calibrate data for ii in range ( nf ): chan = intensity [ ii ,:] if np . nansum ( chan ) == 0. : continue mean = np . nanmean ( chan ) chan [:] = chan [:] / mean chan [:] = chan [:] - 1 var = np . nanvar ( chan ) chan [:] = chan [:] / var # downsampling factors ds = 384 sub_factor = 4 # downsample if necessary if ds > 1 : new_num_spectra = int ( nt / ds ) num_to_trim = nt % ds if num_to_trim > 0 : intensity = intensity [:,: - num_to_trim ] intensity = np . array ( np . column_stack ( [ np . mean ( intensities , axis = 1 ) for intensities \\ in np . hsplit ( intensity , new_num_spectra )])) nf , nt = intensity . shape # subband if necessary if sub_factor > 1 : intensity = np . nanmean ( intensity . reshape ( - 1 , sub_factor , intensity . shape [ 1 ]), axis = 1 ) freq = np . nanmean ( freq . reshape ( - 1 , sub_factor ), axis = 1 ) time_s = np . arange ( tstart , tstop - dt * ds , dt * ds ) variance = np . nanvar ( intensity , axis = 1 ) # zap outlier channels intensity [ variance > 0.004 , ... ] = 0. # plot waterfall plt . imshow ( intensity , origin = \"lower\" , interpolation = \"nearest\" , aspect = \"auto\" ) plt . savefig ( \"aro_wfall.png\" )","title":"Algonquin Radio Observatory Detection"},{"location":"data-formats/","text":"The CHIME/FRB Experiment either the msgpack data format to store raw channelized intensity data, npz file format for processed intensity or baseband data and the CHIME/Pulsar Experiment uses the filterbank data format. For more information on the instrument parameters refer to The CHIME Fast Radio Burst Project: System Overview . msgpack \u00b6 msgpack data is the beamformed and channelized intensity data which consists of 16384 frequency channels at 1ms cadence. This data is scaled, offset, and packed into 8-bit integers files each consisting of 1.00663296s worth of data. In order to read and uncompress the msgpack data into numpy arrays, checkout the cfod python package. filterbank \u00b6 Filterbank data for the fast radio bursts presented in the data release were analyzed using pubicly availaible packages presto and sigproc . npz \u00b6 A dictionary-like object with lazy-loading of files in the zipped archive, for further reading see official numpy documentation . See the code snippets section for more details on paper specific details. h5 \u00b6 The Hierarchical Data Format version 5 ( HDF5 ), is an open source file format that supports large, complex, heterogeneous data. HDF5 uses a file directory like structure that allows you to organize data within the file in many different structured ways, as you might do with files on your computer","title":"Formats"},{"location":"data-formats/#msgpack","text":"msgpack data is the beamformed and channelized intensity data which consists of 16384 frequency channels at 1ms cadence. This data is scaled, offset, and packed into 8-bit integers files each consisting of 1.00663296s worth of data. In order to read and uncompress the msgpack data into numpy arrays, checkout the cfod python package.","title":"msgpack"},{"location":"data-formats/#filterbank","text":"Filterbank data for the fast radio bursts presented in the data release were analyzed using pubicly availaible packages presto and sigproc .","title":"filterbank"},{"location":"data-formats/#npz","text":"A dictionary-like object with lazy-loading of files in the zipped archive, for further reading see official numpy documentation . See the code snippets section for more details on paper specific details.","title":"npz"},{"location":"data-formats/#h5","text":"The Hierarchical Data Format version 5 ( HDF5 ), is an open source file format that supports large, complex, heterogeneous data. HDF5 uses a file directory like structure that allows you to organize data within the file in many different structured ways, as you might do with files on your computer","title":"h5"},{"location":"data-releases/","text":"Release Description Data Release 01 Detection of Fast Radio Bursts at Radio Frequencies Down to 400 MHz link 02 A Second Repeating Fast Radio Burst link 03 Periodic activity from a fast radio burst source link 04 A bright millisecond-duration radio burst from a Galactic magnetar link 05 CHIME/FRB Catalog link 06 CHIME/FRB Injections link","title":"Releases"},{"location":"exposure/","text":"Author: Pragya Chawla Below we provide a sample script for creating an exposure map from CHIME/FRB Catalog 1 Data. This example uses the healpy package to project the exposure map onto the 2D plane and serves as an example to create both a high and low resolution exposure maps. This utility is also provided through the CHIME/FRB Open Data python project. You can find the exposure data in Canfar here . cfod from cfod.analysis import exposure fname = \"exposure_int_20180828_20191001_transit_U_beam_FWHM-600_res_4s_0.86_arcmin.npz\" exposure . render ( filepath = fname ) Creating an exposure map for both upper and lower transits import numpy as np import matplotlib.pyplot as plt import healpy as hp from astropy.coordinates import SkyCoord import astropy.units as u fname_u = \"exposure_int_20180828_20190702_transit_L_beam_FWHM-600_res_4s_0.86_arcmin.npz\" #Upper Transit fname_l = \"exposure_int_20180828_20190702_transit_U_beam_FWHM-600_res_4s_0.86_arcmin.npz\" #Lower Transit with np . load ( fname_u ) as data : exposure = data [ \"exposure\" ] #setting parameters for map resolution # spatial nside = 4096 npix = hp . nside2npix ( nside ) # temporal t_res = 4 # Initializing a healpy map hpxmap = np . zeros ( npix , dtype = np . float ) hpxmap [ 0 : len ( exposure )] += t_res * exposure / ( 3600. ) #seconds to hours hpxmap [ hpxmap == 0 ] = hp . UNSEEN #masking pixels with zero exposure # Plotting hp . mollview ( hpxmap , coord = [ 'C' , 'G' ], norm = 'log' , unit = \"Hours\" ) # Check exposure time in hours for FRB 20121102A coord = SkyCoord ( \"05:31:58.70\" , \"+33:08:52.5\" , frame = 'icrs' , unit = u . deg ) print ( \"Exposure (in hours): %.2f \" % hpxmap [ hp . ang2pix ( nside , coord . ra . deg , coord . dec . deg , lonlat = True )]) ### Obtaining a lower resolution map ### nside_out = 1024 print ( \"Resolution of new map : %.2f arcmin\" % ( hp . nside2resol ( nside_out , arcmin = True ))) # Degrade healpix resolution to nside_out hpxmap_dg = hp . ud_grade ( hpxmap , nside_out ) hp . mollview ( hpxmap_dg , coord = [ 'C' , 'G' ], norm = 'log' , unit = \"Hours\" ) Hint nside_out Varying nside_out parameter below will change the resolution. The nside parameter for the current map is 4096. You can switch to a lower value. However, do not use an nside lower than 512 as you would not be nyquist sampling the CHIME/FRB beam pattern in that case. hpxmap Your HEALpix map will live here. hpxmap_dg Your downgraded HEALpix map will live here. hp.mollview Plots a Mollweide projection of your HEALpix map.","title":"Make an Exposure Map"},{"location":"injections/","text":"Author: Marcus Merryfield The injections dataset used for catalog 1 is separated into two files, available in the data releases section . The first encompasses the full set of 5 million synthetic FRBs which were generated from population distributions based on The First CHIME/FRB Catalog. The second encompasses a subset of these 5 million bursts (~85,000 total) which were actually injected into the live CHIME/FRB intensity data stream. The first file is available as an hdf5 file, while the second is available as a pickle file intended to be read by the pandas library as a DataFrame . Read in the 5 million synthetic pulses import h5py fn = \"chimefrb_catalog1_injections_full.h5\" datafile = h5py . File ( fn , 'r' ) # datafile.keys() will show the sets of data available: # ['frb', 'freq', 'injection_format', 'to_inject', 'to_inject_fit_spec_coeffs'] # Create datasets: 'frb' dset_frb = datafile [ 'frb' ] data_frb = dset_frb [()] # 'freq' dset_freq = datafile [ 'freq' ] data_freq = dset_freq [()] # 'injection_format' dset_inj_format = datafile [ 'injection_format' ] data_inj_format = dset_inj_format [ 'frb' ][()] # 'to_inject' dset_to_inj = datafile [ 'to_inject' ] data_to_inj = dset_to_inj [()] # 'to_inject_fit_spec_coeffs' dset_speccoeffs = datafile [ 'to_inject_fit_spec_coeffs' ] data_speccoeffs = dset_speccoeffs [()] MetaData descriptions Description for each of the datafile keys: frb : The dataset for all 5 million FRBs (hint: empty tuples retrieve all data for hdf5 datasets). The data_frb.dtype shows which attributes are available in this dataset: loc_ind : The index of the sky location chosen for a given FRB. (TODO: is this interpretation correct, and is the information of sky location available anywhere? I guess through x and y beam coords? When I sort the array ( sorted(data_frb['loc_ind']) ), lots of repeated positions...) dm : The DM of a given FRB, in pc/cm^3. width : The intrinsic width of a given FRB, in s. scat_ref : The scattering time of a given FRB, in s, at a reference frequency of (?) (TODO: reference frequency of scattering time? At least I think that's what _ref refers to!) spec_coeffs : The array of three spectral coefficients for an FRB. The three indices of spec_coeffs give the log normalization (index 0), spectral index (index 1), spectral running (index 2) (TODO: Very uncertain about these! Definitely needs double checking... Mainly the index 0, as in data_inj_format , I can see spindex matches index 1 and running matches index 2) x : The CHIME/FRB beam model x coordinate for the given FRB y : The CHIME/FRB beam model y coordinate for the given FRB ra , dec , to_inf , and toa_inf_offset are unused freq : The dataset of 1024 frequencies (~400-800 MHz) used for determining the spectral properties for each FRB. injection_format : A goup which has one key containing a dataset ( datafile['injection_format']['frb'] ) with information for the 5 million FRBs in the format expected by the injection API. The data_inj_format.dtype shows which attributes are available in this dataset: beam_no : The CHIME/FRB beam number for the injection. Given as -1 for the majority of events, as they were not put up for injection. For the frbs which were put up for injection, there are four beam columns: the zeroeth column has beams 0-255 , the first has beams 1000-1255 , the second has beams 2000-2255 , and the third has beams 3000-3255 . injection_program_id : The name of the injection program used to identify sets of injected bursts. In this data, the id has not been filled yet, and it has been temporarily populated with the index. beam_x and beam_y : Same as x and y for the frb key. dm : Same as in the frb key. tau_1_ghz : The scattering time referenced to 1 GHz, in ?? (TODO: is this ms or s? I want to say ms based on values but unsure) pulse_width_ms : The intrinsic width of a given FRB, in ms. fluence : The fluence of a given FRB, in Jy ms. spindex and running : Same as index 1 and 2 of spec_coeffs for the frb key. to_inject : The boolean stating whether or not the burst made the cut into the to_inject dataset. injected : The boolean stating whether a given burst has yet been injected. Note that since this information was updated in a different file, all values here are False . to_inject : The dataset of ~97,000 bursts which are a subset of the 5 million that passed the SNR estimate cut to go up for injection. Note only ~85,000 of these were injected, as some injections were lost due to networking issues. frb_ind : The index in the injection_format corresponding to a given to_inject burst. beam_id : Same as beam_no in the injection_format key. snr_estimate : The estimated signal-to-noise of the injected events, determining whether the event would be put up for injection, calculated using the radiometer equation. For the to_inject dataset, the cutoff SNR was set to 20. While this is significantly higher than the SNR cutoff of 9 used in L1 for the majority of the First CHIME/FRB Catalog, the adjustment was necessary because the estimated SNR using the idealized assumptions in the radiometer equation was far too optimistic compared to actual detection SNRs in initial tests. fluence_spectrum : An array with 1024 fluence values from 400 to 800 MHz, giving the time-integrated fluence spectrum of a synthesized FRB. to_inject_fit_spec_coeffs : The array of fit spectral coefficients for the ~97,000 to_inject events. The array indices are the same as given for spec_coeffs in the frb dataset. These fits were used as the best estimate of what spectral coefficients would be recovered from CHIME/FRB intensity data, based on the fluence_spectrum of the to_inject bursts. (TODO: A little unsure of this definition!) Read in the ~85,000 injected events import numpy as np import pandas as pd # Read in the pickle file as a pandas DataFrame fn = \"chimefrb_catalog1_injections.p\" data = pd . read_pickle ( fn ) # Now separate the data into categories: detected, non-detected, and RFI snr_threshold = 9. rfi_threshold = 5. high_snr_override = 100. # Make a detection mask following CHIME/FRB pipeline logic detected_mask = np . logical_and . reduce ( ( data . bonsai_snr . values > snr_threshold , np . logical_or ( data . l2_rfi_grade . values > rfi_threshold , data . bonsai_snr . values > high_snr_override ) ) ) # Create arrays of detected & non-detected injections det = data [ detected_mask ] nondet = data [ ~ detected_mask ] # Make an RFI mask, where RFI are the subset of non-detections which had # SNRs above the SNR threshold rfi_mask = np . logical_and ( pd . notna ( nondet . l2_rfi_grade ), nondet . bonsai_snr . values > snr_threshold ) # Create array of RFI injections & update non-detected injections rfi = nondet [ rfi_mask ] nondet = nondet [ ~ rfi_mask ] MetaData descriptions Descriptions for each of the columns in the DataFrame (listed via data.keys() ): beam_x : The x position of the injection in CHIME/FRB beam coordinates. The CHIME/FRB beam model is called at an (x,y) coordinate pair to include the forward modelled effect of the beam on the synthetic pulses. beam_y : The y position of the injection in CHIME/FRB beam coordinates. beams : An array of CHIME/FRB beam numbers which the synthetic pulse was injected into. For the First CHIME/FRB Catalog, injections were performed in single beams only. There are four beam columns: the zeroeth column has beams 0-255 , the first has beams 1000-1255 , the second has beams 2000-2255 , and the third has beams 3000-3255 . bonsai_snr : The signal-to-noise ratio (SNR) reported by CHIME/FRB's L1 pipeline. For the majority of the observing period in the First CHIME/FRB Catalog, the detection threshold was at an SNR of 9. dm_det and dm_inj : The detection DM as reported by the L1 pipeline ( _det , if available) and the synthetic pulse's injected DM ( _inj ), in pc/cm^3. dm_err_det : The error in the DM as reported by the L1 pipeline, in pc/cm^3. Note that DM errors are discrete as a function of L1 tree index. dm_gal_ne_2001_max and dm_gal_ymw_2016_max : The maximum DM along the line of site estimated by the NE2001 and YMW16 Galactic DM models, in pc/cm^3. The detected position for synthetic pulses is approximately the center of the beam which they were injected into, since the injections were only performed in single beams. fluence_jy_ms_inj : The estimated injection fluence of the synthetic pulse, in Jy ms. l1_rfi_grade : The RFI grade (scale of 10) reported by the L1 pipeline. l2_rfi_grade : The RFI grade (scale of 10) reported by the L2/L3 pipeline. The threshold for a detection to be considered astrophysical (as opposed to RFI) is 5. pos_dec_deg_det and pos_ra_deg_det : The approximate RA and Dec positions of the detections, in degrees. As injections were performed in single beams, represents approximate the RA and Dec of the beam center at the time of detection. pulse_width_ms_det and pulse_width_ms_inj : The detected pulse width as reported by the L1 pipeline and the synthetic pulse's injected intrinsic width, in ms. Note that L1 does not record which width bin had the highest SNR detection, so the detected width is reported as 2x the size of the time bins in the detection tree. spectral_index_det and spectral_index_inj : The detected spectral index as reported by the L1 pipeline and the synthetic pulse's injected spectral index. L1 only reports two possible spectral indices: +3, or -3. spectral_running_inj : The synthetic pulse's injected spectral 'running', using the running power-law with which CHIME/FRB models real detections. Note that since intensity data is not saved for injected events and L1 only considers a regular power-law weighting there is no detected value for spectral running. t_err_ms_det : The approximate timing error from L1 for the detected pulse, in ms. t_utc_det , t_utc_expected , and t_utc_inj : The UTC time of the detection as reported by the L1 pipeline, the expected UTC time of synthetic pulse detection before injection, and the UTC time which the synthetic pulse was actually injected. tau_1_ghz_ms_inj : The scattering index at 1 GHz of the synthetic pulse, in ms. tree_index_det : The tree index of the detection. Tree index is indexed starting at zero, going to a maximum of four, with each sequential tree increasing the temporal binning by a power of two.","title":"Read the Injection Data"},{"location":"localization/","text":"Author: Alex Josephy Localizations are key to understanding FRBs and this tutorial will show you how to plot localizations from CHIME/FRB Catalog Data. All of the code provided in this tutorial, is also availaible through the CHIME/FRB Open Data python package. cfod from cfod.routines import localizer localize = localizer . Localize ( filename = ` FRB20180725A_localization . h5 ` ) localize . plot () localize . countours () Following Python packages are required complete this tutorial: h5py , numpy , healpy , and matplotlib . Loading in localization data \u00b6 The localization data are stored in an HDF5 format. We include various views of the underlying probability distribution, which should be useful for different situations (e.g. healpix maps, contours lists). Example # Load in packages import h5py as h5 import numpy as np import healpy as hp import matplotlib.pyplot as plt # Load in the HDF5 file. f = h5 . File ( 'example.h5' , 'r' ) # The following function just summarizes the HDF5 file structure: def describe ( group , recurse = False ): \"\"\" Prints info on the contents of an hdf5 group \"\"\" print ( group . name ) # First print header-like attributes (if exist) if group . attrs : print ( ' \\n attrs: {' ) for key , value in group . attrs . items (): if key in [ 'comments' , 'history' ]: print ( ' %s :' % key ) for line in value : print ( ' ' + str ( line )) else : print ( ' %s :' % key , value ) if group . attrs : print ( ' }' ) # Then print constituent groups & datasets print () for key , value in group . items (): if isinstance ( value , h5 . Group ): if recurse : print ( '-' * 60 ) describe ( value , True ) else : print ( ' ' + key + '/' ) else : print ( ' ' + key + ':' , value . shape , value . dtype ) print () ROOT Attributes \u00b6 The attributes at the root level include some basic parameters: TNS name, the positional values reported in the Catalog table, coordinate system details, and galactic coordinates for convenience. ROOT describe(f['/']) # See hint 1 f['healpix'].attrs['comments'] # See hints below Hint The output from the first line above should be: attrs: { tns_name: FRB20181224D ra: 182.45 ra_hms: 12h09m48s ra_error: 0.197 dec: 54.85 dec_dms: 54d51m00s dec_error: 0.213 glon: 135.42455191200924 glat: 61.256833554798746 frame: ICRS epoch: J2000 units: degrees comments: Reported errors are at the 68% CL. R.A. errors have been scaled by cos(dec). Regions reported here are for the mainlobe island. See further data products for sidelobe islands. } healpix/ projection/ contours/ Hint The output from the second line above should be: array(['Sparse representation of a HEALPix map.', 'ipix := pixel indices (given nside and ordering scheme).', 'CL := confidence level. Any pixel with a CL less than', '0.XX is within the XX% credible region.'], dtype=object) HEALPix \u00b6 A sparse representation of a HEALPix map, where pixels with effectively zero probability have been discarded (typically ~99.99% of the sky). The same resolution is used as the exposure maps (nside = 4096, giving a pixel area of ~0.7 square arcmins). HEALPix describe(f['/healpix']) Hint The output from the line above should be. /healpix attrs: { nside: 4096 ordering: nested comments: Sparse representation of a HEALPix map. ipix := pixel indices (given nside and ordering scheme). CL := confidence level. Any pixel with a CL less than 0.XX is within the XX% credible region. } ipix: (174835,) int64 CL: (174835,) float32 Sampling the Localization Region \u00b6 Example usage of HEALPix nside = f['healpix'].attrs['nside'] ipix, CL = f['healpix/ipix'][()], f['healpix/CL'][()] # example 1: get locations of pixels within 90% confidence bounds # note that initializing the full healpix map is not necessary here ra, dec = hp.pix2ang(nside, ipix[CL < 0.9], nest=True, lonlat=True) # example 2: sampling pixels with weighting sampled = np.random.choice(ipix, 30000, p=(1-CL)/(1-CL).sum()) ra, dec = hp.pix2ang(nside, sampled, nest=True, lonlat=True) PROJECTION \u00b6 A Gnomonic projection of the HEALPix map is included for convenient visualization. This projection method projects from the sphere onto a tangent plane, where the tangent point is centered on the target location. This is an appropriate choice given the ~degree scale of these uncertainty regions. The tangent plane that defines the projection is centered on the highest S/N beam. PROJECTION describe(f['/projection']) Hint /projection attrs: { clon: 182.44863891601562 clon_hms: 12h09m48s clat: 54.858444213867195 clat_dms: 54d51m30s reso: 0.5 xsize: 600 ysize: 120 comments: Gnomonic projection of the HEALPix map, centered around the beam with the highest S/N. Made with healpy.projector.GnomonicProj } data: (120, 600) float32 Making a Localization Plot \u00b6 Example hdr = f [ 'projection' ] . attrs CL = f [ 'projection/data' ][:] extent = np . array ([ - hdr [ 'xsize' ] / 2 , hdr [ 'xsize' ] / 2 , - hdr [ 'ysize' ] / 2 , hdr [ 'ysize' ] / 2 ]) * hdr [ 'reso' ] / 60 plt . rc ( 'font' , family = 'serif' , size = 14 ) plt . figure ( figsize = ( 10 , 4 )) # Note: RA increases to the left! im = plt . imshow ( CL , vmin = 0 , origin = 'lower' , extent = extent , cmap = 'magma' ) plt . contour ( CL , levels = [ 0.68 , 0.95 ], linestyles = [ '-' , '--' ], colors = 'k' , linewidths = 2 , extent = extent ) plt . colorbar ( im , pad = 0.25 , shrink = 0.4 , orientation = 'horizontal' , label = 'Confidence Level' ) plt . arrow ( 2.4 , - 0.4 , 0 , 0.2 , head_width = 0.04 , color = 'k' ) plt . text ( 2.39 , - 0.1 , 'N' , ha = 'center' , size = 10 ) plt . arrow ( 2.4 , - 0.4 , - 0.2 , 0. , head_width = 0.04 , color = 'k' ) plt . text ( 2.1 , - 0.4 , 'E' , va = 'center' , ha = 'right' , size = 10 ) plt . title ( 'Centered @ %.3f , %.2f ' % ( hdr [ 'clon' ], hdr [ 'clat' ])) plt . xlabel ( 'dx (deg)' ) plt . ylabel ( 'dy (deg)' ) Your plot generated from the above script should look similar to this plot: Contours \u00b6 Example describe(f['/contours'], recurse=True) Hint The above example's output should look like the following: /contours attrs: { comments: (R.A., Dec.) contours of common confidence intervals. Islands (labelled ABC...) are ordered with increasing R.A. Contours are extracted from the Gnomonic projection, and have been simplified using the Ramer-Douglas-Peucker algorithm (with an epsilon parameter of 0.2 pixels). } ------------------------------------------------------------ /contours/50 A: (2, 22) float32 B: (2, 30) float32 C: (2, 38) float32 ------------------------------------------------------------ /contours/68 A: (2, 24) float32 B: (2, 28) float32 C: (2, 34) float32 D: (2, 43) float32 ------------------------------------------------------------ /contours/90 A: (2, 34) float32 B: (2, 51) float32 C: (2, 46) float32 ------------------------------------------------------------ /contours/95 A: (2, 41) float32 B: (2, 54) float32 C: (2, 48) float32 Making a Contour Plot\u00b6 \u00b6 Example # example 0: getting points ra , dec = f [ 'contours/68/A' ] # example 2: plotting contours plt . figure ( figsize = ( 10 , 2 )) for name , contour in f [ 'contours/68' ] . items (): contour = contour [:] plt . plot ( * contour ) plt . plot ( * contour . mean ( 1 ), 'wo' , mec = 'k' , ms = 20 , alpha = 0.5 ) plt . text ( * contour . mean ( 1 ), s = name , ha = 'center' , va = 'center' ) for contour in f [ 'contours/95' ] . values (): plt . plot ( * contour [:], '--' ) plt . xlim ( * plt . xlim ()[:: - 1 ]) plt . xlabel ( 'R.A. (deg)' ) plt . ylabel ( 'Dec. (deg)' ) Your plot generated from the above script should look similar to this plot:","title":"Make a Localization Plot"},{"location":"localization/#loading-in-localization-data","text":"The localization data are stored in an HDF5 format. We include various views of the underlying probability distribution, which should be useful for different situations (e.g. healpix maps, contours lists). Example # Load in packages import h5py as h5 import numpy as np import healpy as hp import matplotlib.pyplot as plt # Load in the HDF5 file. f = h5 . File ( 'example.h5' , 'r' ) # The following function just summarizes the HDF5 file structure: def describe ( group , recurse = False ): \"\"\" Prints info on the contents of an hdf5 group \"\"\" print ( group . name ) # First print header-like attributes (if exist) if group . attrs : print ( ' \\n attrs: {' ) for key , value in group . attrs . items (): if key in [ 'comments' , 'history' ]: print ( ' %s :' % key ) for line in value : print ( ' ' + str ( line )) else : print ( ' %s :' % key , value ) if group . attrs : print ( ' }' ) # Then print constituent groups & datasets print () for key , value in group . items (): if isinstance ( value , h5 . Group ): if recurse : print ( '-' * 60 ) describe ( value , True ) else : print ( ' ' + key + '/' ) else : print ( ' ' + key + ':' , value . shape , value . dtype ) print ()","title":"Loading in localization data"},{"location":"localization/#root-attributes","text":"The attributes at the root level include some basic parameters: TNS name, the positional values reported in the Catalog table, coordinate system details, and galactic coordinates for convenience. ROOT describe(f['/']) # See hint 1 f['healpix'].attrs['comments'] # See hints below Hint The output from the first line above should be: attrs: { tns_name: FRB20181224D ra: 182.45 ra_hms: 12h09m48s ra_error: 0.197 dec: 54.85 dec_dms: 54d51m00s dec_error: 0.213 glon: 135.42455191200924 glat: 61.256833554798746 frame: ICRS epoch: J2000 units: degrees comments: Reported errors are at the 68% CL. R.A. errors have been scaled by cos(dec). Regions reported here are for the mainlobe island. See further data products for sidelobe islands. } healpix/ projection/ contours/ Hint The output from the second line above should be: array(['Sparse representation of a HEALPix map.', 'ipix := pixel indices (given nside and ordering scheme).', 'CL := confidence level. Any pixel with a CL less than', '0.XX is within the XX% credible region.'], dtype=object)","title":"ROOT Attributes"},{"location":"localization/#healpix","text":"A sparse representation of a HEALPix map, where pixels with effectively zero probability have been discarded (typically ~99.99% of the sky). The same resolution is used as the exposure maps (nside = 4096, giving a pixel area of ~0.7 square arcmins). HEALPix describe(f['/healpix']) Hint The output from the line above should be. /healpix attrs: { nside: 4096 ordering: nested comments: Sparse representation of a HEALPix map. ipix := pixel indices (given nside and ordering scheme). CL := confidence level. Any pixel with a CL less than 0.XX is within the XX% credible region. } ipix: (174835,) int64 CL: (174835,) float32","title":"HEALPix"},{"location":"localization/#sampling-the-localization-region","text":"Example usage of HEALPix nside = f['healpix'].attrs['nside'] ipix, CL = f['healpix/ipix'][()], f['healpix/CL'][()] # example 1: get locations of pixels within 90% confidence bounds # note that initializing the full healpix map is not necessary here ra, dec = hp.pix2ang(nside, ipix[CL < 0.9], nest=True, lonlat=True) # example 2: sampling pixels with weighting sampled = np.random.choice(ipix, 30000, p=(1-CL)/(1-CL).sum()) ra, dec = hp.pix2ang(nside, sampled, nest=True, lonlat=True)","title":"Sampling the Localization Region"},{"location":"localization/#projection","text":"A Gnomonic projection of the HEALPix map is included for convenient visualization. This projection method projects from the sphere onto a tangent plane, where the tangent point is centered on the target location. This is an appropriate choice given the ~degree scale of these uncertainty regions. The tangent plane that defines the projection is centered on the highest S/N beam. PROJECTION describe(f['/projection']) Hint /projection attrs: { clon: 182.44863891601562 clon_hms: 12h09m48s clat: 54.858444213867195 clat_dms: 54d51m30s reso: 0.5 xsize: 600 ysize: 120 comments: Gnomonic projection of the HEALPix map, centered around the beam with the highest S/N. Made with healpy.projector.GnomonicProj } data: (120, 600) float32","title":"PROJECTION"},{"location":"localization/#making-a-localization-plot","text":"Example hdr = f [ 'projection' ] . attrs CL = f [ 'projection/data' ][:] extent = np . array ([ - hdr [ 'xsize' ] / 2 , hdr [ 'xsize' ] / 2 , - hdr [ 'ysize' ] / 2 , hdr [ 'ysize' ] / 2 ]) * hdr [ 'reso' ] / 60 plt . rc ( 'font' , family = 'serif' , size = 14 ) plt . figure ( figsize = ( 10 , 4 )) # Note: RA increases to the left! im = plt . imshow ( CL , vmin = 0 , origin = 'lower' , extent = extent , cmap = 'magma' ) plt . contour ( CL , levels = [ 0.68 , 0.95 ], linestyles = [ '-' , '--' ], colors = 'k' , linewidths = 2 , extent = extent ) plt . colorbar ( im , pad = 0.25 , shrink = 0.4 , orientation = 'horizontal' , label = 'Confidence Level' ) plt . arrow ( 2.4 , - 0.4 , 0 , 0.2 , head_width = 0.04 , color = 'k' ) plt . text ( 2.39 , - 0.1 , 'N' , ha = 'center' , size = 10 ) plt . arrow ( 2.4 , - 0.4 , - 0.2 , 0. , head_width = 0.04 , color = 'k' ) plt . text ( 2.1 , - 0.4 , 'E' , va = 'center' , ha = 'right' , size = 10 ) plt . title ( 'Centered @ %.3f , %.2f ' % ( hdr [ 'clon' ], hdr [ 'clat' ])) plt . xlabel ( 'dx (deg)' ) plt . ylabel ( 'dy (deg)' ) Your plot generated from the above script should look similar to this plot:","title":"Making a Localization Plot"},{"location":"localization/#contours","text":"Example describe(f['/contours'], recurse=True) Hint The above example's output should look like the following: /contours attrs: { comments: (R.A., Dec.) contours of common confidence intervals. Islands (labelled ABC...) are ordered with increasing R.A. Contours are extracted from the Gnomonic projection, and have been simplified using the Ramer-Douglas-Peucker algorithm (with an epsilon parameter of 0.2 pixels). } ------------------------------------------------------------ /contours/50 A: (2, 22) float32 B: (2, 30) float32 C: (2, 38) float32 ------------------------------------------------------------ /contours/68 A: (2, 24) float32 B: (2, 28) float32 C: (2, 34) float32 D: (2, 43) float32 ------------------------------------------------------------ /contours/90 A: (2, 34) float32 B: (2, 51) float32 C: (2, 46) float32 ------------------------------------------------------------ /contours/95 A: (2, 41) float32 B: (2, 54) float32 C: (2, 48) float32","title":"Contours"},{"location":"localization/#making-a-contour-plot","text":"Example # example 0: getting points ra , dec = f [ 'contours/68/A' ] # example 2: plotting contours plt . figure ( figsize = ( 10 , 2 )) for name , contour in f [ 'contours/68' ] . items (): contour = contour [:] plt . plot ( * contour ) plt . plot ( * contour . mean ( 1 ), 'wo' , mec = 'k' , ms = 20 , alpha = 0.5 ) plt . text ( * contour . mean ( 1 ), s = name , ha = 'center' , va = 'center' ) for contour in f [ 'contours/95' ] . values (): plt . plot ( * contour [:], '--' ) plt . xlim ( * plt . xlim ()[:: - 1 ]) plt . xlabel ( 'R.A. (deg)' ) plt . ylabel ( 'Dec. (deg)' ) Your plot generated from the above script should look similar to this plot:","title":"Making a Contour Plot\u00b6"},{"location":"scientific/","text":"Coming Soon...","title":"Scientific"},{"location":"technical/","text":"Coming Soon...","title":"Technical"},{"location":"voevents-faq/","text":"Frequently Asked Questions \u00b6 Common Questions \u00b6 How do I connect to the CHIME/FRB VOEvent Service? The service requires a (free) subscription that can be requested here . We just received a VOEvent, is it a FRB? Not every alert will represent a true FRB! Because alerts are published in real-time they are only verified by a human after you reveive the VOEvent. To check the status of a particular alert, join or start a discussion here . We used the service for follow-up observations, what should we do next? We ask that you cite any CHIME/FRB VOEvents that were used to trigger your follow-up observations by their VOEvent IVORN and in addition cite the usage of the Service with the following statement: This research has made use of the CHIME/FRB VOEvent Service. How do we get help regarding issues about the service Please consult our GitHub community discussion page here . You can search for existing issues first to see if your problem, or similar, has already been solved or is being actively investigated; otherwise, consider starting a discussion there. How can I contact the CHIME/FRB team for quick questions? Please check to see if your question is answered here . If not, consider starting a new discussion, and a CHIME/FRB team member will help out in the forum in a timely manner. VOEvent Service Questions \u00b6 Connection Issues If you are having problems connecting to the Service, you can try these solutions that have been ranked in order of severity/complexity. Request Subscription Check your records whether you have an active subscription. This would have required filling the subscription form which provides a receipt to the email address that requested it. Activation Time Provide atleast 3 working days since submitting the subscription request, thereby allowing enough time for CHIME/FRB to activate your subscription. Valid IP Address Check that the IP address of the machine where you VOEvent broker is running is publicly accessible, not blocked by a firewall, not behind a local router and exactly matches the one you gave in the subscription form. Further Problems Please summarize the problem in a detailed GitHub issue here and be sure to include the following details in the issue. Subscriber details: email address, name, and academic association you gave when filling the subscription form Operating System (e.g. Linux) VOEvent broker software and version (e.g. Comet v 3.1.0) Screenshots or code captures of any messages that your broker reports while trying to subscribe. To obtain detailed diagnostic information, run your VOEvent broker in non-demonized mode and high verbosity - for example, see Comet documentation here . Technical Questions \u00b6 The known_source_name Parameter You may see an integer reported as the name of the source in a subsequent VOEvent, rather than a TNS name. This number is an internal event registration number for CHIME/FRB, indicating that the source is not yet public. Proper credit for CHIME/FRB VOEvent Service Whenever providing credir in publications/ATels, please be sure to use the VOEvent IVORN when referencing individual VOEvents that refer to FRBs, and include the following citation statement: This research has made use of the CHIME/FRB VOEvent Service. Known telescopes/instruments using CHIME/FRB VOEvents The following is a recent list of all observatories, telescopes, and instruments currently using CHIME/FRB VOEvents. Swift -GUANO Hat Creek Radio Observatory VERITAS Does CHIME/FRB issue retractions for spurious events? Real-time VOEvents are verified by humans only after they have been VOEvent has been published. Following human verification, an event may be found to be a false positive signal, for example due to RFI contamination. While the real-time FRB detection pipeline performs multiple levels of RFI excision, it is not a perfect filter. Under the current regime, once per day around 22:00 Pacific Standard Time we will publish retraction VOEvents in bulk for all false positives classified in the previous 24 hour period. How precise and accurate is the localization region in the VOEvent? The real-time localization is reported as an on-sky circle in celestial coordinates. The precision and accurcy of this circular region is sensitive to whether the FRB was detected in one beam or multiple beams. Precision Multi-beam FRB detections typically come with the least precise real-time localization. The error radius can be as large as 1 to 2 degrees, and larger in rare instances. Typically the worst localizations are for events that later turn out to be RFI that was detected in many beams. Single-beam FRB detections are typically circular regions with a radius equal to half the detection beam width at 600 MHz, which is about 0.5 degrees. However, it can be much better in some instances, as low as 10 arcminutes. Accuracy The accuracy of real-time localizations has been evaluated and described in CHIME/FRB Collaboration et al., 2019 , using the method of pulsar analogues. Which FRB parameters are most important? Every subscriber has constructed a potentially unique follow-up campaign. For instance, one may be interested in low dispersion measure (DM) FRBs, while another is interested in follow-up of specific known repeating FRBs. For that reason, the FRB parameters of import vary from one campaign to the next. For example, the dm and snr parameters in every VOEvent can be used with thresholds to trigger on CHIME-detected FRBs that have low DM and high-SNR, to study FRBs that are potentially in the local Universe. In a different scenario, a threshold on timestamp_utc is important for campaigns looking to achieve very low latency follow-up.","title":"FAQs"},{"location":"voevents-faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"voevents-faq/#common-questions","text":"How do I connect to the CHIME/FRB VOEvent Service? The service requires a (free) subscription that can be requested here . We just received a VOEvent, is it a FRB? Not every alert will represent a true FRB! Because alerts are published in real-time they are only verified by a human after you reveive the VOEvent. To check the status of a particular alert, join or start a discussion here . We used the service for follow-up observations, what should we do next? We ask that you cite any CHIME/FRB VOEvents that were used to trigger your follow-up observations by their VOEvent IVORN and in addition cite the usage of the Service with the following statement: This research has made use of the CHIME/FRB VOEvent Service. How do we get help regarding issues about the service Please consult our GitHub community discussion page here . You can search for existing issues first to see if your problem, or similar, has already been solved or is being actively investigated; otherwise, consider starting a discussion there. How can I contact the CHIME/FRB team for quick questions? Please check to see if your question is answered here . If not, consider starting a new discussion, and a CHIME/FRB team member will help out in the forum in a timely manner.","title":"Common Questions"},{"location":"voevents-faq/#voevent-service-questions","text":"Connection Issues If you are having problems connecting to the Service, you can try these solutions that have been ranked in order of severity/complexity. Request Subscription Check your records whether you have an active subscription. This would have required filling the subscription form which provides a receipt to the email address that requested it. Activation Time Provide atleast 3 working days since submitting the subscription request, thereby allowing enough time for CHIME/FRB to activate your subscription. Valid IP Address Check that the IP address of the machine where you VOEvent broker is running is publicly accessible, not blocked by a firewall, not behind a local router and exactly matches the one you gave in the subscription form. Further Problems Please summarize the problem in a detailed GitHub issue here and be sure to include the following details in the issue. Subscriber details: email address, name, and academic association you gave when filling the subscription form Operating System (e.g. Linux) VOEvent broker software and version (e.g. Comet v 3.1.0) Screenshots or code captures of any messages that your broker reports while trying to subscribe. To obtain detailed diagnostic information, run your VOEvent broker in non-demonized mode and high verbosity - for example, see Comet documentation here .","title":"VOEvent Service Questions"},{"location":"voevents-faq/#technical-questions","text":"The known_source_name Parameter You may see an integer reported as the name of the source in a subsequent VOEvent, rather than a TNS name. This number is an internal event registration number for CHIME/FRB, indicating that the source is not yet public. Proper credit for CHIME/FRB VOEvent Service Whenever providing credir in publications/ATels, please be sure to use the VOEvent IVORN when referencing individual VOEvents that refer to FRBs, and include the following citation statement: This research has made use of the CHIME/FRB VOEvent Service. Known telescopes/instruments using CHIME/FRB VOEvents The following is a recent list of all observatories, telescopes, and instruments currently using CHIME/FRB VOEvents. Swift -GUANO Hat Creek Radio Observatory VERITAS Does CHIME/FRB issue retractions for spurious events? Real-time VOEvents are verified by humans only after they have been VOEvent has been published. Following human verification, an event may be found to be a false positive signal, for example due to RFI contamination. While the real-time FRB detection pipeline performs multiple levels of RFI excision, it is not a perfect filter. Under the current regime, once per day around 22:00 Pacific Standard Time we will publish retraction VOEvents in bulk for all false positives classified in the previous 24 hour period. How precise and accurate is the localization region in the VOEvent? The real-time localization is reported as an on-sky circle in celestial coordinates. The precision and accurcy of this circular region is sensitive to whether the FRB was detected in one beam or multiple beams. Precision Multi-beam FRB detections typically come with the least precise real-time localization. The error radius can be as large as 1 to 2 degrees, and larger in rare instances. Typically the worst localizations are for events that later turn out to be RFI that was detected in many beams. Single-beam FRB detections are typically circular regions with a radius equal to half the detection beam width at 600 MHz, which is about 0.5 degrees. However, it can be much better in some instances, as low as 10 arcminutes. Accuracy The accuracy of real-time localizations has been evaluated and described in CHIME/FRB Collaboration et al., 2019 , using the method of pulsar analogues. Which FRB parameters are most important? Every subscriber has constructed a potentially unique follow-up campaign. For instance, one may be interested in low dispersion measure (DM) FRBs, while another is interested in follow-up of specific known repeating FRBs. For that reason, the FRB parameters of import vary from one campaign to the next. For example, the dm and snr parameters in every VOEvent can be used with thresholds to trigger on CHIME-detected FRBs that have low DM and high-SNR, to study FRBs that are potentially in the local Universe. In a different scenario, a threshold on timestamp_utc is important for campaigns looking to achieve very low latency follow-up.","title":"Technical Questions"},{"location":"voevents/","text":"CHIME/FRB Virtual Observatory Events \u00b6 Calling all follow-up observers! CHIME/FRB is pleased to provide public real-time alerts of new CHIME-detected FRBs through a Virtual Observatory Event (VOEvent) based service. As a first step, checkout the presentation below. Next Steps Check out the FAQ section for answers to common questions and what to do if you cannot find an answer you are looking for.You can also download the slide deck from the video presentation, and a Jupyter Notebook with detailed code examples for working with VOEvents.","title":"Welcome"},{"location":"voevents/#chimefrb-virtual-observatory-events","text":"Calling all follow-up observers! CHIME/FRB is pleased to provide public real-time alerts of new CHIME-detected FRBs through a Virtual Observatory Event (VOEvent) based service. As a first step, checkout the presentation below. Next Steps Check out the FAQ section for answers to common questions and what to do if you cannot find an answer you are looking for.You can also download the slide deck from the video presentation, and a Jupyter Notebook with detailed code examples for working with VOEvents.","title":"CHIME/FRB Virtual Observatory Events"},{"location":"waterfall/","text":"CHIME/FRB Waterfall Data \u00b6 Author: Pranav Sanghvi This tutorial will help you get aquainted with the CHIME/FRB Catalog waterfall data. In this tutorial, the data file FRB20180725A_waterfall.h5 was used, which contains data for FRB 20180725A. This data can be downloaded from the CHIME/FRB Open Data Release . To download additional data, visit the Canadian Astronomy Data Center . All of the code provided in this tutorial, is also availaible through the CHIME/FRB Open Data python package. cfod from cfod.routines import waterfaller wfall = Waterfaller ( filename = ` FRB20180725A_waterfall . h5 ` ) wfall . plot () wfall . cal_plot ( savepath = \"/some/path\" ) Read hdf5 files \u00b6 The user can use the file_name variable to store the name of the file that contains the FRB data to be analyzed. Be sure to follow the instructions for downloading the hdf5 file for each FRB as desrcibed above. The file should be placed in the same directory as this notebook, or the full path should be specified in file_name . Example file_name = \"FRB20180725A_waterfall.h5\" data = h5py . File ( file_name , \"r\" ) Explore the data files \u00b6 File Contents list ( data . keys ()) >>> [ 'frb' ] Metadata list ( data [ \"frb\" ] . keys ()) >>> [ 'calibrated_wfall' , 'extent' , 'model_spec' , 'model_ts' , 'model_wfall' , 'plot_freq' , 'plot_time' , 'spec' , 'ts' , 'wfall' ] Metadata Description extent : the extent of the waterfall data plot_freq : The values of the frequecy indices in \\(\\rm{MHz}\\) plot_time : The value of the time indices in \\(\\rm{\\mu s}\\) wfall : waterfall data model_wfall : waterfall from fitted data spec : Dynamic Spectrum model_spec : model-fitted dynamic spectrum ts : time series data model_ts : model-fitted time series caliberated_wfall : The waterfall data with calibration applied Unpack the Data data = data [ \"frb\" ] eventname = data . attrs [ \"tns_name\" ] . decode () wfall = data [ \"wfall\" ][:] model_wfall = data [ \"model_wfall\" ][:] plot_time = data [ \"plot_time\" ][:] plot_freq = data [ \"plot_freq\" ][:] ts = data [ \"ts\" ][:] model_ts = data [ \"model_ts\" ][:] spec = data [ \"spec\" ][:] model_spec = data [ \"model_spec\" ][:] extent = data [ \"extent\" ][:] dm = data . attrs [ \"dm\" ][()] scatterfit = data . attrs [ \"scatterfit\" ][()] cal_obs_date = data . attrs [ \"calibration_observation_date\" ] . decode () cal_source_name = data . attrs [ \"calibration_source_name\" ] . decode () cal_wfall = data [ \"calibrated_wfall\" ][:] dt = np . median ( np . diff ( plot_time )) # the delta (time) between time bins # this value is the same for both caliberated and uncalibrated data Removing the Radio Frequency Interference \u00b6 This process sets any frequency channel that has a higher variance than the mean variance (averaged across all frequency channels) to a NaN value using np.nan . RFI Removal q1 = np . nanquantile ( spec , 0.25 ) q3 = np . nanquantile ( spec , 0.75 ) iqr = q3 - q1 # additional masking of channels with RFI rfi_masking_var_factor = 3 channel_variance = np . nanvar ( wfall , axis = 1 ) mean_channel_variance = np . nanmean ( channel_variance ) with np . errstate ( invalid = \"ignore\" ): rfi_mask = ( channel_variance > \\ rfi_masking_var_factor * mean_channel_variance ) \\ | ( spec [:: - 1 ] < q1 - 1.5 * iqr ) | ( spec [:: - 1 ] > q3 + 1.5 * iqr ) wfall [ rfi_mask , ... ] = np . nan model_wfall [ rfi_mask , ... ] = np . nan spec [ rfi_mask [:: - 1 ]] = np . nan # remake time-series after RFI masking ts = np . nansum ( wfall , axis = 0 ) model_ts = np . nansum ( model_wfall , axis = 0 ) Determine the Peaks and SNR of the Pulse \u00b6 Peaks are identified after boxcar convolution. Pulse Properties def boxcar_kernel ( width ): width = int ( round ( width , 0 )) return np . ones ( width , dtype = \"float32\" ) / np . sqrt ( width ) def find_burst ( ts , min_width = 1 , max_width = 128 ): min_width = int ( min_width ) max_width = int ( max_width ) # do not search widths bigger than timeseries widths = list ( range ( min_width , min ( max_width + 1 , len ( ts ) - 2 ))) # envelope finding snrs = np . empty_like ( widths , dtype = float ) peaks = np . empty_like ( widths , dtype = int ) for i in range ( len ( widths )): convolved = scipy . signal . convolve ( ts , boxcar_kernel ( widths [ i ]), mode = \"same\" ) peaks [ i ] = np . nanargmax ( convolved ) snrs [ i ] = convolved [ peaks [ i ]] best_idx = np . nanargmax ( snrs ) return peaks [ best_idx ], widths [ best_idx ], snrs [ best_idx ] peak, width, snr = find_burst(ts) print(f\"Peak: {peak} at time sample, Width = {width*dt} ms, SNR = {snr}\") Visualize the Dynamic Spectra \u00b6 First and foremost, we need to bin the frequency data before we visualize it. Bin Frequency Data def bin_freq_channels ( data , fbin_factor = 4 ): num_chan = data . shape [ 0 ] if num_chan % fbin_factor != 0 : raise ValueError ( \"frequency binning factor `fbin_factor` should be even\" ) data = np . nanmean ( data . reshape (( num_chan // fbin_factor , fbin_factor ) + data . shape [ 1 :]), axis = 1 ) return data # bin frequency channels such that we have 16,384/16 = 1024 frequency channels wfall = bin_freq_channels ( wfall , 16 ) Plot the Dynamic Spectrum fig = plt . figure ( figsize = ( 6 , 6 )) ## Set up the image grid gs = gridspec . GridSpec ( ncols = 2 , nrows = 2 , figure = fig , width_ratios = [ 3 , 1 ], height_ratios = [ 1 , 3 ], hspace = 0.0 , wspace = 0.0 ) data_im = plt . subplot ( gs [ 2 ]) data_ts = plt . subplot ( gs [ 0 ], sharex = data_im ) data_spec = plt . subplot ( gs [ 3 ], sharey = data_im ) ### time stamps relative to the peak peak_idx = np . argmax ( ts ) extent [ 0 ] = extent [ 0 ] - plot_time [ peak_idx ] extent [ 1 ] = extent [ 1 ] - plot_time [ peak_idx ] plot_time -= plot_time [ peak_idx ] # prepare time-series for histogramming plot_time -= dt / 2. plot_time = np . append ( plot_time , plot_time [ - 1 ] + dt ) cmap = plt . cm . viridis ### plot dynamic spectrum wfall [ np . isnan ( wfall )] = np . nanmedian ( wfall ) # replace nans in the data with the data median # use standard deviation of residuals to set color scale vmin = np . nanpercentile ( wfall , 1 ) vmax = np . nanpercentile ( wfall , 99 ) data_im . imshow ( wfall , aspect = \"auto\" , interpolation = \"none\" , extent = extent , vmin = vmin , vmax = vmax , cmap = cmap ) ### plot time-series data_ts . plot ( plot_time , np . append ( ts , ts [ - 1 ]), color = \"tab:gray\" , drawstyle = \"steps-post\" ) ### plot spectrum data_spec . plot ( spec , plot_freq , color = \"tab:gray\" ) ### plot model time-series and spectrum if scatterfit : data_spec . plot ( model_spec , plot_freq , color = cmap ( 0.25 )) data_ts . plot ( plot_time , np . append ( model_ts , model_ts [ - 1 ]), color = cmap ( 0.25 ), drawstyle = \"steps-post\" , lw = 2 ) else : data_spec . plot ( model_spec , plot_freq , color = cmap ( 0.5 )) data_ts . plot ( plot_time , np . append ( model_ts , model_ts [ - 1 ]), color = cmap ( 0.5 ), drawstyle = \"steps-post\" , lw = 1 ) ## BEautify plot # remove some labels and ticks for neatness plt . setp ( data_ts . get_xticklabels (), visible = False ) data_ts . set_yticklabels ([], visible = True ) data_ts . set_yticks ([]) data_ts . set_xlim ( extent [ 0 ], extent [ 1 ]) plt . setp ( data_spec . get_yticklabels (), visible = False ) data_spec . set_xticklabels ([], visible = True ) data_spec . set_xticks ([]) data_spec . set_ylim ( extent [ 2 ], extent [ 3 ]) plt . setp ( data_im . get_xticklabels (), fontsize = 9 ) plt . setp ( data_im . get_yticklabels (), fontsize = 9 ) #### highlighting the width of the pulse data_ts . axvspan ( max ( plot_time . min (), plot_time [ peak ] + 0.5 * dt \\ - ( 0.5 * width ) * dt ), min ( plot_time . max (), plot_time [ peak ] + 0.5 * dt \\ + ( 0.5 * width ) * dt ), facecolor = \"tab:blue\" , edgecolor = None , alpha = 0.1 ) ##### add event ID and DM labels xlim = data_ts . get_xlim () ylim = data_ts . get_ylim () # add 20% extra white space at the top span = np . abs ( ylim [ 1 ]) + np . abs ( ylim [ 0 ]) data_ts . set_ylim ( ylim [ 0 ], ylim [ 1 ] + 0.2 * span ) ylim = data_ts . get_ylim () ypos = ( ylim [ 1 ] - ylim [ 0 ]) * 0.9 + ylim [ 0 ] xpos = ( xlim [ 1 ] - xlim [ 0 ]) * 0.98 + extent [ 0 ] data_ts . text ( xpos , ypos , \" {} \\n DM: {:.1f} pc/cc \\n SNR: {:.2f} \" . format ( eventname , dm , snr ), ha = \"right\" , va = \"top\" , fontsize = 9 ) data_im . locator_params ( axis = \"x\" , min_n_ticks = 3 ) data_im . set_yticks ([ 400 , 500 , 600 , 700 , 800 ]) data_im . set_ylabel ( \"Frequency [MHz]\" , fontsize = 9 ) data_im . set_xlabel ( \"Time [ms]\" , fontsize = 9 ) #savefigure plt . savefig ( \" {} _wfall.png\" . format ( eventname ), dpi = 300 , bbox_inches = \"tight\" ) Plotting Calibrated Data \u00b6 Within the hdf5 file is the calibrated waterfall data, allowing one to plot the data as measured in Janskys. Extract the Waterfall and Construct the Time Series cal_ts = np . nanmean ( cal_wfall , axis = 0 ) cal_wfall [ np . isnan ( cal_wfall )] = np . nanmedian ( cal_wfall ) # replace nans in the data with the data median #bin frequency channels such that we have 16,384/16 = 1024 frequency channels cal_wfall = bin_freq_channels ( cal_wfall , 16 ) vmin = np . nanpercentile ( cal_wfall , 1 ) vmax = np . nanpercentile ( cal_wfall , 99 ) times = np . arange ( len ( cal_ts )) * dt peak_idx = np . argmax ( cal_ts ) times -= times [ peak_idx ] times -= dt / 2. extent [ 0 ] = times [ 0 ] extent [ 1 ] = times [ - 1 ] fig = plt . figure ( figsize = ( 5 , 5 ), constrained_layout = True ) layout = \"\"\" A C \"\"\" ax_dict = fig . subplot_mosaic ( layout ) ax_dict [ \"A\" ] . imshow ( cal_wfall , aspect = \"auto\" , vmin = vmin , vmax = vmax , extent = extent ) ax_dict [ \"A\" ] . set_title ( f \"Waterfall of { eventname } \\n Calibrated to { cal_source_name } on { cal_obs_date } \" ) ax_dict [ \"A\" ] . set_yticks ([ 400 , 500 , 600 , 700 , 800 ]) ax_dict [ \"C\" ] . plot ( times , cal_ts , drawstyle = \"steps-post\" ) ax_dict [ \"C\" ] . set_xlabel ( \"Time [ms]\" ) ax_dict [ \"C\" ] . set_title ( f \"Time Series of { eventname } \\n Calibrated to { cal_source_name } on { cal_obs_date } \\ \\n Peak flux = { cal_ts [ peak_idx ] : .3f } Jy\" ) ax_dict [ \"A\" ] . set_ylabel ( \"Frequency [MHz]\" ) ax_dict [ \"C\" ] . set_ylabel ( \"Flux [Jy]\" )","title":"Make a Waterfall Plot"},{"location":"waterfall/#chimefrb-waterfall-data","text":"Author: Pranav Sanghvi This tutorial will help you get aquainted with the CHIME/FRB Catalog waterfall data. In this tutorial, the data file FRB20180725A_waterfall.h5 was used, which contains data for FRB 20180725A. This data can be downloaded from the CHIME/FRB Open Data Release . To download additional data, visit the Canadian Astronomy Data Center . All of the code provided in this tutorial, is also availaible through the CHIME/FRB Open Data python package. cfod from cfod.routines import waterfaller wfall = Waterfaller ( filename = ` FRB20180725A_waterfall . h5 ` ) wfall . plot () wfall . cal_plot ( savepath = \"/some/path\" )","title":"CHIME/FRB Waterfall Data"},{"location":"waterfall/#read-hdf5-files","text":"The user can use the file_name variable to store the name of the file that contains the FRB data to be analyzed. Be sure to follow the instructions for downloading the hdf5 file for each FRB as desrcibed above. The file should be placed in the same directory as this notebook, or the full path should be specified in file_name . Example file_name = \"FRB20180725A_waterfall.h5\" data = h5py . File ( file_name , \"r\" )","title":"Read hdf5 files"},{"location":"waterfall/#explore-the-data-files","text":"File Contents list ( data . keys ()) >>> [ 'frb' ] Metadata list ( data [ \"frb\" ] . keys ()) >>> [ 'calibrated_wfall' , 'extent' , 'model_spec' , 'model_ts' , 'model_wfall' , 'plot_freq' , 'plot_time' , 'spec' , 'ts' , 'wfall' ] Metadata Description extent : the extent of the waterfall data plot_freq : The values of the frequecy indices in \\(\\rm{MHz}\\) plot_time : The value of the time indices in \\(\\rm{\\mu s}\\) wfall : waterfall data model_wfall : waterfall from fitted data spec : Dynamic Spectrum model_spec : model-fitted dynamic spectrum ts : time series data model_ts : model-fitted time series caliberated_wfall : The waterfall data with calibration applied Unpack the Data data = data [ \"frb\" ] eventname = data . attrs [ \"tns_name\" ] . decode () wfall = data [ \"wfall\" ][:] model_wfall = data [ \"model_wfall\" ][:] plot_time = data [ \"plot_time\" ][:] plot_freq = data [ \"plot_freq\" ][:] ts = data [ \"ts\" ][:] model_ts = data [ \"model_ts\" ][:] spec = data [ \"spec\" ][:] model_spec = data [ \"model_spec\" ][:] extent = data [ \"extent\" ][:] dm = data . attrs [ \"dm\" ][()] scatterfit = data . attrs [ \"scatterfit\" ][()] cal_obs_date = data . attrs [ \"calibration_observation_date\" ] . decode () cal_source_name = data . attrs [ \"calibration_source_name\" ] . decode () cal_wfall = data [ \"calibrated_wfall\" ][:] dt = np . median ( np . diff ( plot_time )) # the delta (time) between time bins # this value is the same for both caliberated and uncalibrated data","title":"Explore the data files"},{"location":"waterfall/#removing-the-radio-frequency-interference","text":"This process sets any frequency channel that has a higher variance than the mean variance (averaged across all frequency channels) to a NaN value using np.nan . RFI Removal q1 = np . nanquantile ( spec , 0.25 ) q3 = np . nanquantile ( spec , 0.75 ) iqr = q3 - q1 # additional masking of channels with RFI rfi_masking_var_factor = 3 channel_variance = np . nanvar ( wfall , axis = 1 ) mean_channel_variance = np . nanmean ( channel_variance ) with np . errstate ( invalid = \"ignore\" ): rfi_mask = ( channel_variance > \\ rfi_masking_var_factor * mean_channel_variance ) \\ | ( spec [:: - 1 ] < q1 - 1.5 * iqr ) | ( spec [:: - 1 ] > q3 + 1.5 * iqr ) wfall [ rfi_mask , ... ] = np . nan model_wfall [ rfi_mask , ... ] = np . nan spec [ rfi_mask [:: - 1 ]] = np . nan # remake time-series after RFI masking ts = np . nansum ( wfall , axis = 0 ) model_ts = np . nansum ( model_wfall , axis = 0 )","title":"Removing the Radio Frequency Interference"},{"location":"waterfall/#determine-the-peaks-and-snr-of-the-pulse","text":"Peaks are identified after boxcar convolution. Pulse Properties def boxcar_kernel ( width ): width = int ( round ( width , 0 )) return np . ones ( width , dtype = \"float32\" ) / np . sqrt ( width ) def find_burst ( ts , min_width = 1 , max_width = 128 ): min_width = int ( min_width ) max_width = int ( max_width ) # do not search widths bigger than timeseries widths = list ( range ( min_width , min ( max_width + 1 , len ( ts ) - 2 ))) # envelope finding snrs = np . empty_like ( widths , dtype = float ) peaks = np . empty_like ( widths , dtype = int ) for i in range ( len ( widths )): convolved = scipy . signal . convolve ( ts , boxcar_kernel ( widths [ i ]), mode = \"same\" ) peaks [ i ] = np . nanargmax ( convolved ) snrs [ i ] = convolved [ peaks [ i ]] best_idx = np . nanargmax ( snrs ) return peaks [ best_idx ], widths [ best_idx ], snrs [ best_idx ] peak, width, snr = find_burst(ts) print(f\"Peak: {peak} at time sample, Width = {width*dt} ms, SNR = {snr}\")","title":"Determine the Peaks and SNR of the Pulse"},{"location":"waterfall/#visualize-the-dynamic-spectra","text":"First and foremost, we need to bin the frequency data before we visualize it. Bin Frequency Data def bin_freq_channels ( data , fbin_factor = 4 ): num_chan = data . shape [ 0 ] if num_chan % fbin_factor != 0 : raise ValueError ( \"frequency binning factor `fbin_factor` should be even\" ) data = np . nanmean ( data . reshape (( num_chan // fbin_factor , fbin_factor ) + data . shape [ 1 :]), axis = 1 ) return data # bin frequency channels such that we have 16,384/16 = 1024 frequency channels wfall = bin_freq_channels ( wfall , 16 ) Plot the Dynamic Spectrum fig = plt . figure ( figsize = ( 6 , 6 )) ## Set up the image grid gs = gridspec . GridSpec ( ncols = 2 , nrows = 2 , figure = fig , width_ratios = [ 3 , 1 ], height_ratios = [ 1 , 3 ], hspace = 0.0 , wspace = 0.0 ) data_im = plt . subplot ( gs [ 2 ]) data_ts = plt . subplot ( gs [ 0 ], sharex = data_im ) data_spec = plt . subplot ( gs [ 3 ], sharey = data_im ) ### time stamps relative to the peak peak_idx = np . argmax ( ts ) extent [ 0 ] = extent [ 0 ] - plot_time [ peak_idx ] extent [ 1 ] = extent [ 1 ] - plot_time [ peak_idx ] plot_time -= plot_time [ peak_idx ] # prepare time-series for histogramming plot_time -= dt / 2. plot_time = np . append ( plot_time , plot_time [ - 1 ] + dt ) cmap = plt . cm . viridis ### plot dynamic spectrum wfall [ np . isnan ( wfall )] = np . nanmedian ( wfall ) # replace nans in the data with the data median # use standard deviation of residuals to set color scale vmin = np . nanpercentile ( wfall , 1 ) vmax = np . nanpercentile ( wfall , 99 ) data_im . imshow ( wfall , aspect = \"auto\" , interpolation = \"none\" , extent = extent , vmin = vmin , vmax = vmax , cmap = cmap ) ### plot time-series data_ts . plot ( plot_time , np . append ( ts , ts [ - 1 ]), color = \"tab:gray\" , drawstyle = \"steps-post\" ) ### plot spectrum data_spec . plot ( spec , plot_freq , color = \"tab:gray\" ) ### plot model time-series and spectrum if scatterfit : data_spec . plot ( model_spec , plot_freq , color = cmap ( 0.25 )) data_ts . plot ( plot_time , np . append ( model_ts , model_ts [ - 1 ]), color = cmap ( 0.25 ), drawstyle = \"steps-post\" , lw = 2 ) else : data_spec . plot ( model_spec , plot_freq , color = cmap ( 0.5 )) data_ts . plot ( plot_time , np . append ( model_ts , model_ts [ - 1 ]), color = cmap ( 0.5 ), drawstyle = \"steps-post\" , lw = 1 ) ## BEautify plot # remove some labels and ticks for neatness plt . setp ( data_ts . get_xticklabels (), visible = False ) data_ts . set_yticklabels ([], visible = True ) data_ts . set_yticks ([]) data_ts . set_xlim ( extent [ 0 ], extent [ 1 ]) plt . setp ( data_spec . get_yticklabels (), visible = False ) data_spec . set_xticklabels ([], visible = True ) data_spec . set_xticks ([]) data_spec . set_ylim ( extent [ 2 ], extent [ 3 ]) plt . setp ( data_im . get_xticklabels (), fontsize = 9 ) plt . setp ( data_im . get_yticklabels (), fontsize = 9 ) #### highlighting the width of the pulse data_ts . axvspan ( max ( plot_time . min (), plot_time [ peak ] + 0.5 * dt \\ - ( 0.5 * width ) * dt ), min ( plot_time . max (), plot_time [ peak ] + 0.5 * dt \\ + ( 0.5 * width ) * dt ), facecolor = \"tab:blue\" , edgecolor = None , alpha = 0.1 ) ##### add event ID and DM labels xlim = data_ts . get_xlim () ylim = data_ts . get_ylim () # add 20% extra white space at the top span = np . abs ( ylim [ 1 ]) + np . abs ( ylim [ 0 ]) data_ts . set_ylim ( ylim [ 0 ], ylim [ 1 ] + 0.2 * span ) ylim = data_ts . get_ylim () ypos = ( ylim [ 1 ] - ylim [ 0 ]) * 0.9 + ylim [ 0 ] xpos = ( xlim [ 1 ] - xlim [ 0 ]) * 0.98 + extent [ 0 ] data_ts . text ( xpos , ypos , \" {} \\n DM: {:.1f} pc/cc \\n SNR: {:.2f} \" . format ( eventname , dm , snr ), ha = \"right\" , va = \"top\" , fontsize = 9 ) data_im . locator_params ( axis = \"x\" , min_n_ticks = 3 ) data_im . set_yticks ([ 400 , 500 , 600 , 700 , 800 ]) data_im . set_ylabel ( \"Frequency [MHz]\" , fontsize = 9 ) data_im . set_xlabel ( \"Time [ms]\" , fontsize = 9 ) #savefigure plt . savefig ( \" {} _wfall.png\" . format ( eventname ), dpi = 300 , bbox_inches = \"tight\" )","title":"Visualize the Dynamic Spectra"},{"location":"waterfall/#plotting-calibrated-data","text":"Within the hdf5 file is the calibrated waterfall data, allowing one to plot the data as measured in Janskys. Extract the Waterfall and Construct the Time Series cal_ts = np . nanmean ( cal_wfall , axis = 0 ) cal_wfall [ np . isnan ( cal_wfall )] = np . nanmedian ( cal_wfall ) # replace nans in the data with the data median #bin frequency channels such that we have 16,384/16 = 1024 frequency channels cal_wfall = bin_freq_channels ( cal_wfall , 16 ) vmin = np . nanpercentile ( cal_wfall , 1 ) vmax = np . nanpercentile ( cal_wfall , 99 ) times = np . arange ( len ( cal_ts )) * dt peak_idx = np . argmax ( cal_ts ) times -= times [ peak_idx ] times -= dt / 2. extent [ 0 ] = times [ 0 ] extent [ 1 ] = times [ - 1 ] fig = plt . figure ( figsize = ( 5 , 5 ), constrained_layout = True ) layout = \"\"\" A C \"\"\" ax_dict = fig . subplot_mosaic ( layout ) ax_dict [ \"A\" ] . imshow ( cal_wfall , aspect = \"auto\" , vmin = vmin , vmax = vmax , extent = extent ) ax_dict [ \"A\" ] . set_title ( f \"Waterfall of { eventname } \\n Calibrated to { cal_source_name } on { cal_obs_date } \" ) ax_dict [ \"A\" ] . set_yticks ([ 400 , 500 , 600 , 700 , 800 ]) ax_dict [ \"C\" ] . plot ( times , cal_ts , drawstyle = \"steps-post\" ) ax_dict [ \"C\" ] . set_xlabel ( \"Time [ms]\" ) ax_dict [ \"C\" ] . set_title ( f \"Time Series of { eventname } \\n Calibrated to { cal_source_name } on { cal_obs_date } \\ \\n Peak flux = { cal_ts [ peak_idx ] : .3f } Jy\" ) ax_dict [ \"A\" ] . set_ylabel ( \"Frequency [MHz]\" ) ax_dict [ \"C\" ] . set_ylabel ( \"Flux [Jy]\" )","title":"Plotting Calibrated Data"}]}