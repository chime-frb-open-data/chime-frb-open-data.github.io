{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to open data releases for the Canadian Hydroden Intensity Mapping Experiment / Fast Radio Bursts . The purposes of this website is to be the central resource for providing access to the data and accompanying code snippets required to get the community started on exploring the CHIME/FRB datasets. Data Releases Tutorials Package Support Note You may use the data presented in this website for publications; however, we ask that you cite the relevant CHIME/FRB Collaboration papers.","title":"Get Started"},{"location":"catalog/","text":"Authors: Alice Curtin, Sabrina Berger In order to take a closer look at the CHIME/FRB Catalog Data download it from our official website which is updated regularly. The catalog data is available in CSV and FITS file formats. Read in CHIME/FRB Catalog Pandas Dataframe import numpy as np import pandas as pd # csv file columns (extracted directly from the list that is presented in the Catalog 1 paper) col_list = [ 'tns_name' , 'previous_name' , 'repeater_name' , 'ra' , 'ra_err' , 'ra_notes' , 'dec' , 'dec_err' , 'dec_notes' , 'gl' , 'gb' , 'exp_up' , 'exp_up_err' , 'exp_up_notes' , 'exp_low' , 'exp_low_err' , 'exp_low_notes' , 'bonsai_snr' , 'bonsai_dm' , 'low_ft_68' , 'up_ft_68' , 'low_ft_95' , 'up_ft_95' , 'snr_fitb' , 'dm_fitb' , 'dm_fitb_err' , 'dm_exc_ne2001' , 'dm_exc_ymw16' , 'bc_width' , 'scat_time' , 'scat_time_err' , 'flux' , 'flux_err' , 'flux_notes' , 'fluence' , 'fluence_err' , 'fluence_notes' , 'sub_num' , 'mjd_400' , 'mjd_400_err' , 'mjd_inf' , 'mjd_inf_err' , 'width_fitb' , 'width_fitb_err' , 'sp_idx' , 'sp_idx_err' , 'sp_run' , 'sp_run_err' , 'high_freq' , 'low_freq' , 'peak_freq' , 'excluded_flag' ] # reading in the csv file df = pd . read_csv ( \"catalog1.csv\" , usecols = col_list ) # The Catalog 1 Data now lives in df. You can view they keys for examples with: print ( df . keys ()) FITS # use the fits file reader in astropy from astropy.io import fits fits_catalog = \"catalog1.fits\" # open the fits file with a context manager, i.e., using with with fits . open ( fits_catalog ) as hdul : # The Catalog 1 Data now lives in hdul. You can view more information about the file with: hdul . info () In addition to downloading the catalog manually, it is also availaible through the open source CHIME/FRB Open Data python package. cfod Dictionary from cfod import catalog data = catalog . as_dict () JSON from cfod import catalog data = catalog . as_json () List from cfod import catalog data = catalog . as_list () Dataframe from cfod import catalog data = catalog . as_dataframe () FITS from cfod import catalog data = catalog . as_dataframe ()","title":"Read in Catalog"},{"location":"code/","text":"Release 01 | FRBs @ 400MHz \u00b6 For reading msgpack data provided in this release, headover to the CHIME/FRB Open Data Python package. Example Single File from cfod import chime_intensity as ci fn = ` astro_5941664_20180406203904337770_beam0147_00245439_02 . msgpack ` intensity , weights , fpga0 , fpgaN , binning , frame0_nano , nrfifreq , rfi_mask = ci . unpack_data ( fn ) Multiple files from cfod import chime_intensity as ci fns = [ 'file1' , 'file2' , 'file3' ] intensity , weights , fpga0s , fpgaNs , binning , rfi_mask , frame0_nanos = ci . unpack_datafiles ( fns ) Hint where, intensity is a 2D Intensity array. weights are the corresponding 2D array weights to the intensity array. fpga0 (int) is start fpga count of the data chunk. (Internally used to track time, can be ignored). The fpga count increments at the rate of 2.56us. fpgaN (int) is number of fpga counts in the data chunk read binning (int) is the downsampling of the data from the ringbuffer frame0_nano is the conversion from fpga timestamp to utc timestamp (Currently not supported.) nrfifreq is the number of frequences masked by the realtime rfi system (Currently not supported.) rfi_mask is currently not supported Release 03 | Periodic FRB \u00b6 The burst dynamic spectra (waterfalls) for this release constitutes of both intensity and baseband data, stored in npz files. Intensity Data \u00b6 The waterfalls from intensity data have file names burst_*_16k_wfall.npz and are stored at the full resolution of 16,384 frequency channels over 400 MHz with a 0.00098304s time resolution, dedispersed to 348.82 pc cm-3. Baseband Data \u00b6 The waterfalls derived from complex voltage (baseband) data have file names burst_*_bb_1k_wfall.npz and are stored at a resolution of 1,024 frequency channels over 400 MHz with time resolution and dedispersed to the DM as in Extended Data Figure 1 of the paper: {40.96, 40.96, 20.48, 81.92}us and {348.78, 348.82, 348.82, 348.86} pc cm-3. In all cases zapped channels due to RFI are replaced by np.nan . Note that the bursts are too dim too see in individual frequency channels at full resolution. In the paper, we have downsampled the data in frequency for visualization. Data can be accessed and displayed in Python as, e.g.: Example import matplotlib.pyplot as plt import numpy as np fname = \"burst_9_bb_1k_wfall.npz\" data = np . load ( fname ) wfall = data [ \"wfall\" ] dt_s = data [ \"dt_s\" ] center_freq_mhz = data [ \"center_freq_mhz\" ] df_mhz = center_freq_mhz [ 1 ] - center_freq_mhz [ 0 ] plt . imshow ( wfall , origin = \"lower\" , aspect = \"auto\" , interpolation = \"nearest\" , extent = ( 0 , dt_s * wfall . shape [ 1 ], center_freq_mhz [ 0 ] - df_mhz / 2. , center_freq_mhz [ - 1 ] + df_mhz / 2. ) ) plt . xlabel ( \"Time [s]\" ) plt . ylabel ( \"Frequency [MHz]\" ) Release 04 | Galactic Magnetar \u00b6 CHIME/FRB Detection \u00b6 These files for this data release have names chimefrb_SGR1935+2154_20200428_B????.npz where B???? corresponds to the CHIME/FRB beam that recorded that data. The highest S/N detection was made by beam 2067 . The data have a 1024 frequency channels over 400 MHz with time resolution of 0.98304ms and are dedispersed to 332.7206 pc cm-3 . In all cases zapped channels due to RFI are replaced by np.nan . Data can be accessed and displayed in Python as using the following code, Example import glob import matplotlib.pyplot as plt import numpy as np fnames = glob . glob ( \"chimefrb_SGR1935+2154_20200428_B????.npz\" ) for fname in fnames : data = np . load ( fname ) print ( data . files ) intensity = data [ \"intensity\" ] times = data [ \"times\" ] frequencies = data [ \"frequencies\" ] plt . figure () plt . imshow ( intensity , aspect = \"auto\" , origin = \"lower\" , interpolation = \"nearest\" ) plt . show () The NumPy arrays stored in the npz files are: Hint center_frequencies : center frequency of each channel, in MHz center_time : center time of each sample, in s df : channel bandwidth, in MHz dm : dispersion measure, in pc cm-3 dt : sampling time, in s fbottom : frequency at the bottom of the band, in MHz frequencies : lower edge of each channel, in MHz ftop : frequency at the top of the band, in MHz intensity : burst dynamic spectrum nchan : number of channels nsamp : number of samples tend : end of the samples, in s times : left edge of each sample, in s tstart : start of the samples, in s Algonquin Radio Observatory Detection \u00b6 This data has been recorded with the 10-m dish at the Algonquin Radio Observatory and is named, aro_SGR1935+2154_20200428_baseband.npz The NumPy arrays stored in the npz file are: Hint V : coherently dedispersed complex voltages, with shape (nt, nf, npol) start_time : start time of the observation, referenced to 800. MHz end_time : end time of the observation, referenced to 800. MHz DM : dispersion measure, in pc cm-3, to which the data is coherently dedispersed Note that the DM to which the data has been coherently dispersed, 332.80925424 pc cm-3 , is slightly different than the optimal DM measured by CHIME, 332.7206 pc cm-3 . Below is an example of reading in complex voltages, determining Stokes parameters, and plotting the total intensity: Example import matplotlib.pyplot as plt import numpy as np def get_stokes ( data ): X = data [:,:, 0 ] Y = data [:,:, 1 ] I = abs ( X ) ** 2 + abs ( Y ) ** 2 Q = abs ( X ) ** 2 - abs ( Y ) ** 2 U = 2 * np . real ( X * np . conj ( Y )) V = - 2 * np . imag ( X * np . conj ( Y )) return I , Q , U , V data = np . load ( \"aro_SGR1935+2154_20200428_baseband.npz\" ) print ( data . files ) cv = data [ \"V\" ] # complex voltages are shaped (nt, nf, npol) nt , nf , _ = cv . shape tstart = np . datetime64 ( str ( data [ \"start_time\" ])) tstop = np . datetime64 ( str ( data [ \"stop_time\" ])) dt = ( tstop - tstart ) / nt dm = data [ \"DM\" ] freq = np . linspace ( 800 , 400 , 1024 , endpoint = False )[:: - 1 ] I , Q , U , V = get_stokes ( cv ) # change shape to (nf, nt) with the bottom frequency at index 0 intensity = np . flipud ( I . T ) # self-calibrate data for ii in range ( nf ): chan = intensity [ ii ,:] if np . nansum ( chan ) == 0. : continue mean = np . nanmean ( chan ) chan [:] = chan [:] / mean chan [:] = chan [:] - 1 var = np . nanvar ( chan ) chan [:] = chan [:] / var # downsampling factors ds = 384 sub_factor = 4 # downsample if necessary if ds > 1 : new_num_spectra = int ( nt / ds ) num_to_trim = nt % ds if num_to_trim > 0 : intensity = intensity [:,: - num_to_trim ] intensity = np . array ( np . column_stack ( [ np . mean ( intensities , axis = 1 ) for intensities \\ in np . hsplit ( intensity , new_num_spectra )])) nf , nt = intensity . shape # subband if necessary if sub_factor > 1 : intensity = np . nanmean ( intensity . reshape ( - 1 , sub_factor , intensity . shape [ 1 ]), axis = 1 ) freq = np . nanmean ( freq . reshape ( - 1 , sub_factor ), axis = 1 ) time_s = np . arange ( tstart , tstop - dt * ds , dt * ds ) variance = np . nanvar ( intensity , axis = 1 ) # zap outlier channels intensity [ variance > 0.004 , ... ] = 0. # plot waterfall plt . imshow ( intensity , origin = \"lower\" , interpolation = \"nearest\" , aspect = \"auto\" ) plt . savefig ( \"aro_wfall.png\" )","title":"Previous Releases"},{"location":"code/#release-01-frbs-400mhz","text":"For reading msgpack data provided in this release, headover to the CHIME/FRB Open Data Python package. Example Single File from cfod import chime_intensity as ci fn = ` astro_5941664_20180406203904337770_beam0147_00245439_02 . msgpack ` intensity , weights , fpga0 , fpgaN , binning , frame0_nano , nrfifreq , rfi_mask = ci . unpack_data ( fn ) Multiple files from cfod import chime_intensity as ci fns = [ 'file1' , 'file2' , 'file3' ] intensity , weights , fpga0s , fpgaNs , binning , rfi_mask , frame0_nanos = ci . unpack_datafiles ( fns ) Hint where, intensity is a 2D Intensity array. weights are the corresponding 2D array weights to the intensity array. fpga0 (int) is start fpga count of the data chunk. (Internally used to track time, can be ignored). The fpga count increments at the rate of 2.56us. fpgaN (int) is number of fpga counts in the data chunk read binning (int) is the downsampling of the data from the ringbuffer frame0_nano is the conversion from fpga timestamp to utc timestamp (Currently not supported.) nrfifreq is the number of frequences masked by the realtime rfi system (Currently not supported.) rfi_mask is currently not supported","title":"Release 01 | FRBs @ 400MHz"},{"location":"code/#release-03-periodic-frb","text":"The burst dynamic spectra (waterfalls) for this release constitutes of both intensity and baseband data, stored in npz files.","title":"Release 03 | Periodic FRB"},{"location":"code/#intensity-data","text":"The waterfalls from intensity data have file names burst_*_16k_wfall.npz and are stored at the full resolution of 16,384 frequency channels over 400 MHz with a 0.00098304s time resolution, dedispersed to 348.82 pc cm-3.","title":"Intensity Data"},{"location":"code/#baseband-data","text":"The waterfalls derived from complex voltage (baseband) data have file names burst_*_bb_1k_wfall.npz and are stored at a resolution of 1,024 frequency channels over 400 MHz with time resolution and dedispersed to the DM as in Extended Data Figure 1 of the paper: {40.96, 40.96, 20.48, 81.92}us and {348.78, 348.82, 348.82, 348.86} pc cm-3. In all cases zapped channels due to RFI are replaced by np.nan . Note that the bursts are too dim too see in individual frequency channels at full resolution. In the paper, we have downsampled the data in frequency for visualization. Data can be accessed and displayed in Python as, e.g.: Example import matplotlib.pyplot as plt import numpy as np fname = \"burst_9_bb_1k_wfall.npz\" data = np . load ( fname ) wfall = data [ \"wfall\" ] dt_s = data [ \"dt_s\" ] center_freq_mhz = data [ \"center_freq_mhz\" ] df_mhz = center_freq_mhz [ 1 ] - center_freq_mhz [ 0 ] plt . imshow ( wfall , origin = \"lower\" , aspect = \"auto\" , interpolation = \"nearest\" , extent = ( 0 , dt_s * wfall . shape [ 1 ], center_freq_mhz [ 0 ] - df_mhz / 2. , center_freq_mhz [ - 1 ] + df_mhz / 2. ) ) plt . xlabel ( \"Time [s]\" ) plt . ylabel ( \"Frequency [MHz]\" )","title":"Baseband Data"},{"location":"code/#release-04-galactic-magnetar","text":"","title":"Release 04 | Galactic Magnetar"},{"location":"code/#chimefrb-detection","text":"These files for this data release have names chimefrb_SGR1935+2154_20200428_B????.npz where B???? corresponds to the CHIME/FRB beam that recorded that data. The highest S/N detection was made by beam 2067 . The data have a 1024 frequency channels over 400 MHz with time resolution of 0.98304ms and are dedispersed to 332.7206 pc cm-3 . In all cases zapped channels due to RFI are replaced by np.nan . Data can be accessed and displayed in Python as using the following code, Example import glob import matplotlib.pyplot as plt import numpy as np fnames = glob . glob ( \"chimefrb_SGR1935+2154_20200428_B????.npz\" ) for fname in fnames : data = np . load ( fname ) print ( data . files ) intensity = data [ \"intensity\" ] times = data [ \"times\" ] frequencies = data [ \"frequencies\" ] plt . figure () plt . imshow ( intensity , aspect = \"auto\" , origin = \"lower\" , interpolation = \"nearest\" ) plt . show () The NumPy arrays stored in the npz files are: Hint center_frequencies : center frequency of each channel, in MHz center_time : center time of each sample, in s df : channel bandwidth, in MHz dm : dispersion measure, in pc cm-3 dt : sampling time, in s fbottom : frequency at the bottom of the band, in MHz frequencies : lower edge of each channel, in MHz ftop : frequency at the top of the band, in MHz intensity : burst dynamic spectrum nchan : number of channels nsamp : number of samples tend : end of the samples, in s times : left edge of each sample, in s tstart : start of the samples, in s","title":"CHIME/FRB Detection"},{"location":"code/#algonquin-radio-observatory-detection","text":"This data has been recorded with the 10-m dish at the Algonquin Radio Observatory and is named, aro_SGR1935+2154_20200428_baseband.npz The NumPy arrays stored in the npz file are: Hint V : coherently dedispersed complex voltages, with shape (nt, nf, npol) start_time : start time of the observation, referenced to 800. MHz end_time : end time of the observation, referenced to 800. MHz DM : dispersion measure, in pc cm-3, to which the data is coherently dedispersed Note that the DM to which the data has been coherently dispersed, 332.80925424 pc cm-3 , is slightly different than the optimal DM measured by CHIME, 332.7206 pc cm-3 . Below is an example of reading in complex voltages, determining Stokes parameters, and plotting the total intensity: Example import matplotlib.pyplot as plt import numpy as np def get_stokes ( data ): X = data [:,:, 0 ] Y = data [:,:, 1 ] I = abs ( X ) ** 2 + abs ( Y ) ** 2 Q = abs ( X ) ** 2 - abs ( Y ) ** 2 U = 2 * np . real ( X * np . conj ( Y )) V = - 2 * np . imag ( X * np . conj ( Y )) return I , Q , U , V data = np . load ( \"aro_SGR1935+2154_20200428_baseband.npz\" ) print ( data . files ) cv = data [ \"V\" ] # complex voltages are shaped (nt, nf, npol) nt , nf , _ = cv . shape tstart = np . datetime64 ( str ( data [ \"start_time\" ])) tstop = np . datetime64 ( str ( data [ \"stop_time\" ])) dt = ( tstop - tstart ) / nt dm = data [ \"DM\" ] freq = np . linspace ( 800 , 400 , 1024 , endpoint = False )[:: - 1 ] I , Q , U , V = get_stokes ( cv ) # change shape to (nf, nt) with the bottom frequency at index 0 intensity = np . flipud ( I . T ) # self-calibrate data for ii in range ( nf ): chan = intensity [ ii ,:] if np . nansum ( chan ) == 0. : continue mean = np . nanmean ( chan ) chan [:] = chan [:] / mean chan [:] = chan [:] - 1 var = np . nanvar ( chan ) chan [:] = chan [:] / var # downsampling factors ds = 384 sub_factor = 4 # downsample if necessary if ds > 1 : new_num_spectra = int ( nt / ds ) num_to_trim = nt % ds if num_to_trim > 0 : intensity = intensity [:,: - num_to_trim ] intensity = np . array ( np . column_stack ( [ np . mean ( intensities , axis = 1 ) for intensities \\ in np . hsplit ( intensity , new_num_spectra )])) nf , nt = intensity . shape # subband if necessary if sub_factor > 1 : intensity = np . nanmean ( intensity . reshape ( - 1 , sub_factor , intensity . shape [ 1 ]), axis = 1 ) freq = np . nanmean ( freq . reshape ( - 1 , sub_factor ), axis = 1 ) time_s = np . arange ( tstart , tstop - dt * ds , dt * ds ) variance = np . nanvar ( intensity , axis = 1 ) # zap outlier channels intensity [ variance > 0.004 , ... ] = 0. # plot waterfall plt . imshow ( intensity , origin = \"lower\" , interpolation = \"nearest\" , aspect = \"auto\" ) plt . savefig ( \"aro_wfall.png\" )","title":"Algonquin Radio Observatory Detection"},{"location":"data-formats/","text":"The CHIME/FRB Experiment either the msgpack data format to store raw channelized intensity data, npz file format for processed intensity or baseband data and the CHIME/Pulsar Experiment uses the filterbank data format. For more information on the instrument parameters refer to The CHIME Fast Radio Burst Project: System Overview . msgpack \u00b6 msgpack data is the beamformed and channelized intensity data which consists of 16384 frequency channels at 1ms cadence. This data is scaled, offset, and packed into 8-bit integers files each consisting of 1.00663296s worth of data. In order to read and uncompress the msgpack data into numpy arrays, checkout the cfod python package. filterbank \u00b6 Filterbank data for the fast radio bursts presented in the data release were analyzed using pubicly availaible packages presto and sigproc . npz \u00b6 A dictionary-like object with lazy-loading of files in the zipped archive, for further reading see official numpy documentation . See the code snippets section for more details on paper specific details.","title":"Formats"},{"location":"data-formats/#msgpack","text":"msgpack data is the beamformed and channelized intensity data which consists of 16384 frequency channels at 1ms cadence. This data is scaled, offset, and packed into 8-bit integers files each consisting of 1.00663296s worth of data. In order to read and uncompress the msgpack data into numpy arrays, checkout the cfod python package.","title":"msgpack"},{"location":"data-formats/#filterbank","text":"Filterbank data for the fast radio bursts presented in the data release were analyzed using pubicly availaible packages presto and sigproc .","title":"filterbank"},{"location":"data-formats/#npz","text":"A dictionary-like object with lazy-loading of files in the zipped archive, for further reading see official numpy documentation . See the code snippets section for more details on paper specific details.","title":"npz"},{"location":"data-releases/","text":"Release Description Data Release 01 Detection of Fast Radio Bursts at Radio Frequencies Down to 400 MHz link 02 A Second Repeating Fast Radio Burst link 03 Periodic activity from a fast radio burst source link 04 A bright millisecond-duration radio burst from a Galactic magnetar link 05 CHIME/FRB Catalog link","title":"Releases"},{"location":"exposure/","text":"Author: Dr. Pragya Chawla Below we provide a sample script for creating an exposure map from CHIME/FRB Catalog 1 Data. This example uses the healpy package to project the exposure map onto the 2D plane and serves as an example tp create both a high and low resolution exposure maps. Creating an exposure map for both upper and lower transits import numpy as np import matplotlib.pyplot as plt import healpy as hp from astropy.coordinates import SkyCoord import astropy.units as u fname_u = \"exposure_int_20180828_20191001_transit_U_beam_FWHM-600_res_4s_0.86_arcmin.npz\" fname_l = \"exposure_int_20180828_20191001_transit_L_beam_FWHM-600_res_4s_0.86_arcmin.npz\" with np . load ( fname_u ) as data : exposure = data [ \"exposure\" ] #setting parameters for map resolution # spatial nside = 4096 npix = hp . nside2npix ( nside ) # temporal t_res = 4 # Initializing a healpy map hpxmap = np . zeros ( npix , dtype = np . float ) hpxmap [ 0 : len ( exposure )] += t_res * exposure / ( 3600. ) #seconds to hours hpxmap [ hpxmap == 0 ] = hp . UNSEEN #masking pixels with zero exposure # Plotting hp . mollview ( hpxmap , coord = [ 'C' , 'G' ], norm = 'log' , unit = \"Hours\" ) # Check exposure time in hours for R1 repeater coord = SkyCoord ( \"05:31:58.70\" , \"+33:08:52.5\" , frame = 'icrs' , unit = u . deg ) print ( \"Exposure (in hours): %.2f \" % hpxmap [ hp . ang2pix ( nside , coord . ra . deg , coord . dec . deg , lonlat = True )]) ### Obtaining a lower resolution map ### nside_out = 1024 print ( \"Resolution of new map : %.2f arcmin\" % ( hp . nside2resol ( nside_out , arcmin = True ))) # Degrade healpix resolution to nside_out hpxmap_dg = hp . ud_grade ( hpxmap , nside_out ) hp . mollview ( hpxmap_dg , coord = [ 'C' , 'G' ], norm = 'log' , unit = \"Hours\" ) Hint nside_out Varying nside_out parameter below will change the resolution. The nside parameter for the current map is 4096. You can switch to a lower value. However, do not use an nside lower than 512 as you would not be nyquist sampling the CHIME/FRB beam pattern in that case. hpxmap Your HEALpix map will live here. hpxmap_dg Your downgraded HEALpix map will live here. hp.mollview Plots a Mollweide projection of your HEALpix map. This utility is also provided through the CHIME/FRB Open Data python project. cfod from cfod.analysis import exposure fname = \"exposure_int_20180828_20191001_transit_U_beam_FWHM-600_res_4s_0.86_arcmin.npz\" exposure . render ( filepath = fname )","title":"Make an Exposure Map"},{"location":"localization/","text":"Author: Alex Josephy Localizations are key to understanding FRBs and this tutorial will show you how to plot localizations from CHIME/FRB Catalog Data. Following Python packages are required complete this tutorial: h5py , numpy , healpy , and matplotlib . Loading in localization data \u00b6 The localization data are stored in an HDF5 format. We include various views of the underlying probability distribution, which should be useful for different situations (e.g. healpix maps, contours lists). Example # Load in packages import h5py as h5 import numpy as np import healpy as hp import matplotlib.pyplot as plt # Load in the HDF5 file. f = h5 . File ( 'example.h5' , 'r' ) # The following function just summarizes the HDF5 file structure: def describe ( group , recurse = False ): \"\"\" Prints info on the contents of an hdf5 group \"\"\" print ( group . name ) # First print header-like attributes (if exist) if group . attrs : print ( ' \\n attrs: {' ) for key , value in group . attrs . items (): if key in [ 'comments' , 'history' ]: print ( ' %s :' % key ) for line in value : print ( ' ' + str ( line )) else : print ( ' %s :' % key , value ) if group . attrs : print ( ' }' ) # Then print constituent groups & datasets print () for key , value in group . items (): if isinstance ( value , h5 . Group ): if recurse : print ( '-' * 60 ) describe ( value , True ) else : print ( ' ' + key + '/' ) else : print ( ' ' + key + ':' , value . shape , value . dtype ) print () ROOT Attributes \u00b6 The attributes at the root level include some basic parameters: TNS name, the positional values reported in the Catalog table, coordinate system details, and galactic coordinates for convenience. ROOT describe(f['/']) # See hint 1 f['healpix'].attrs['comments'] # See hints below Hint The output from the first line above should be: attrs: { tns_name: FRB20181224D ra: 182.45 ra_hms: 12h09m48s ra_error: 0.197 dec: 54.85 dec_dms: 54d51m00s dec_error: 0.213 glon: 135.42455191200924 glat: 61.256833554798746 frame: ICRS epoch: J2000 units: degrees comments: Reported errors are at the 68% CL. R.A. errors have been scaled by cos(dec). Regions reported here are for the mainlobe island. See further data products for sidelobe islands. } healpix/ projection/ contours/ Hint The output from the second line above should be: array(['Sparse representation of a HEALPix map.', 'ipix := pixel indices (given nside and ordering scheme).', 'CL := confidence level. Any pixel with a CL less than', '0.XX is within the XX% credible region.'], dtype=object) HEALPix \u00b6 A sparse representation of a HEALPix map, where pixels with effectively zero probability have been discarded (typically ~99.99% of the sky). The same resolution is used as the exposure maps (nside = 4096, giving a pixel area of ~0.7 square arcmins). HEALPix describe(f['/healpix']) Hint The output from the line above should be. /healpix attrs: { nside: 4096 ordering: nested comments: Sparse representation of a HEALPix map. ipix := pixel indices (given nside and ordering scheme). CL := confidence level. Any pixel with a CL less than 0.XX is within the XX% credible region. } ipix: (174835,) int64 CL: (174835,) float32 Sampling the Localization Region \u00b6 Example usage of HEALPix nside = f['healpix'].attrs['nside'] ipix, CL = f['healpix/ipix'][()], f['healpix/CL'][()] # example 1: get locations of pixels within 90% confidence bounds # note that initializing the full healpix map is not necessary here ra, dec = hp.pix2ang(nside, ipix[CL < 0.9], nest=True, lonlat=True) # example 2: sampling pixels with weighting sampled = np.random.choice(ipix, 30000, p=(1-CL)/(1-CL).sum()) ra, dec = hp.pix2ang(nside, sampled, nest=True, lonlat=True) PROJECTION \u00b6 A Gnomonic projection of the HEALPix map is included for convenient visualization. This projection method projects from the sphere onto a tangent plane, where the tangent point is centered on the target location. This is an appropriate choice given the ~degree scale of these uncertainty regions. The tangent plane that defines the projection is centered on the highest S/N beam. PROJECTION describe(f['/projection']) Hint /projection attrs: { clon: 182.44863891601562 clon_hms: 12h09m48s clat: 54.858444213867195 clat_dms: 54d51m30s reso: 0.5 xsize: 600 ysize: 120 comments: Gnomonic projection of the HEALPix map, centered around the beam with the highest S/N. Made with healpy.projector.GnomonicProj } data: (120, 600) float32 Making a Localization Plot \u00b6 Example hdr = f [ 'projection' ] . attrs CL = f [ 'projection/data' ][:] extent = np . array ([ - hdr [ 'xsize' ] / 2 , hdr [ 'xsize' ] / 2 , - hdr [ 'ysize' ] / 2 , hdr [ 'ysize' ] / 2 ]) * hdr [ 'reso' ] / 60 plt . rc ( 'font' , family = 'serif' , size = 14 ) plt . figure ( figsize = ( 10 , 4 )) # Note: RA increases to the left! im = plt . imshow ( CL , vmin = 0 , origin = 'lower' , extent = extent , cmap = 'magma' ) plt . contour ( CL , levels = [ 0.68 , 0.95 ], linestyles = [ '-' , '--' ], colors = 'k' , linewidths = 2 , extent = extent ) plt . colorbar ( im , pad = 0.25 , shrink = 0.4 , orientation = 'horizontal' , label = 'Confidence Level' ) plt . arrow ( 2.4 , - 0.4 , 0 , 0.2 , head_width = 0.04 , color = 'k' ) plt . text ( 2.39 , - 0.1 , 'N' , ha = 'center' , size = 10 ) plt . arrow ( 2.4 , - 0.4 , - 0.2 , 0. , head_width = 0.04 , color = 'k' ) plt . text ( 2.1 , - 0.4 , 'E' , va = 'center' , ha = 'right' , size = 10 ) plt . title ( 'Centered @ %.3f , %.2f ' % ( hdr [ 'clon' ], hdr [ 'clat' ])) plt . xlabel ( 'dx (deg)' ) plt . ylabel ( 'dy (deg)' ) Your plot generated from the above script should look similar to this plot: Contours \u00b6 Example describe(f['/contours'], recurse=True) Hint The above example's output should look like the following: /contours attrs: { comments: (R.A., Dec.) contours of common confidence intervals. Islands (labelled ABC...) are ordered with increasing R.A. Contours are extracted from the Gnomonic projection, and have been simplified using the Ramer-Douglas-Peucker algorithm (with an epsilon parameter of 0.2 pixels). } ------------------------------------------------------------ /contours/50 A: (2, 22) float32 B: (2, 30) float32 C: (2, 38) float32 ------------------------------------------------------------ /contours/68 A: (2, 24) float32 B: (2, 28) float32 C: (2, 34) float32 D: (2, 43) float32 ------------------------------------------------------------ /contours/90 A: (2, 34) float32 B: (2, 51) float32 C: (2, 46) float32 ------------------------------------------------------------ /contours/95 A: (2, 41) float32 B: (2, 54) float32 C: (2, 48) float32 Making a Contour Plot\u00b6 \u00b6 Example # example 0: getting points ra , dec = f [ 'contours/68/A' ] # example 2: plotting contours plt . figure ( figsize = ( 10 , 2 )) for name , contour in f [ 'contours/68' ] . items (): contour = contour [:] plt . plot ( * contour ) plt . plot ( * contour . mean ( 1 ), 'wo' , mec = 'k' , ms = 20 , alpha = 0.5 ) plt . text ( * contour . mean ( 1 ), s = name , ha = 'center' , va = 'center' ) for contour in f [ 'contours/95' ] . values (): plt . plot ( * contour [:], '--' ) plt . xlim ( * plt . xlim ()[:: - 1 ]) plt . xlabel ( 'R.A. (deg)' ) plt . ylabel ( 'Dec. (deg)' ) Your plot generated from the above script should look similar to this plot:","title":"Make a Localization Plot"},{"location":"localization/#loading-in-localization-data","text":"The localization data are stored in an HDF5 format. We include various views of the underlying probability distribution, which should be useful for different situations (e.g. healpix maps, contours lists). Example # Load in packages import h5py as h5 import numpy as np import healpy as hp import matplotlib.pyplot as plt # Load in the HDF5 file. f = h5 . File ( 'example.h5' , 'r' ) # The following function just summarizes the HDF5 file structure: def describe ( group , recurse = False ): \"\"\" Prints info on the contents of an hdf5 group \"\"\" print ( group . name ) # First print header-like attributes (if exist) if group . attrs : print ( ' \\n attrs: {' ) for key , value in group . attrs . items (): if key in [ 'comments' , 'history' ]: print ( ' %s :' % key ) for line in value : print ( ' ' + str ( line )) else : print ( ' %s :' % key , value ) if group . attrs : print ( ' }' ) # Then print constituent groups & datasets print () for key , value in group . items (): if isinstance ( value , h5 . Group ): if recurse : print ( '-' * 60 ) describe ( value , True ) else : print ( ' ' + key + '/' ) else : print ( ' ' + key + ':' , value . shape , value . dtype ) print ()","title":"Loading in localization data"},{"location":"localization/#root-attributes","text":"The attributes at the root level include some basic parameters: TNS name, the positional values reported in the Catalog table, coordinate system details, and galactic coordinates for convenience. ROOT describe(f['/']) # See hint 1 f['healpix'].attrs['comments'] # See hints below Hint The output from the first line above should be: attrs: { tns_name: FRB20181224D ra: 182.45 ra_hms: 12h09m48s ra_error: 0.197 dec: 54.85 dec_dms: 54d51m00s dec_error: 0.213 glon: 135.42455191200924 glat: 61.256833554798746 frame: ICRS epoch: J2000 units: degrees comments: Reported errors are at the 68% CL. R.A. errors have been scaled by cos(dec). Regions reported here are for the mainlobe island. See further data products for sidelobe islands. } healpix/ projection/ contours/ Hint The output from the second line above should be: array(['Sparse representation of a HEALPix map.', 'ipix := pixel indices (given nside and ordering scheme).', 'CL := confidence level. Any pixel with a CL less than', '0.XX is within the XX% credible region.'], dtype=object)","title":"ROOT Attributes"},{"location":"localization/#healpix","text":"A sparse representation of a HEALPix map, where pixels with effectively zero probability have been discarded (typically ~99.99% of the sky). The same resolution is used as the exposure maps (nside = 4096, giving a pixel area of ~0.7 square arcmins). HEALPix describe(f['/healpix']) Hint The output from the line above should be. /healpix attrs: { nside: 4096 ordering: nested comments: Sparse representation of a HEALPix map. ipix := pixel indices (given nside and ordering scheme). CL := confidence level. Any pixel with a CL less than 0.XX is within the XX% credible region. } ipix: (174835,) int64 CL: (174835,) float32","title":"HEALPix"},{"location":"localization/#sampling-the-localization-region","text":"Example usage of HEALPix nside = f['healpix'].attrs['nside'] ipix, CL = f['healpix/ipix'][()], f['healpix/CL'][()] # example 1: get locations of pixels within 90% confidence bounds # note that initializing the full healpix map is not necessary here ra, dec = hp.pix2ang(nside, ipix[CL < 0.9], nest=True, lonlat=True) # example 2: sampling pixels with weighting sampled = np.random.choice(ipix, 30000, p=(1-CL)/(1-CL).sum()) ra, dec = hp.pix2ang(nside, sampled, nest=True, lonlat=True)","title":"Sampling the Localization Region"},{"location":"localization/#projection","text":"A Gnomonic projection of the HEALPix map is included for convenient visualization. This projection method projects from the sphere onto a tangent plane, where the tangent point is centered on the target location. This is an appropriate choice given the ~degree scale of these uncertainty regions. The tangent plane that defines the projection is centered on the highest S/N beam. PROJECTION describe(f['/projection']) Hint /projection attrs: { clon: 182.44863891601562 clon_hms: 12h09m48s clat: 54.858444213867195 clat_dms: 54d51m30s reso: 0.5 xsize: 600 ysize: 120 comments: Gnomonic projection of the HEALPix map, centered around the beam with the highest S/N. Made with healpy.projector.GnomonicProj } data: (120, 600) float32","title":"PROJECTION"},{"location":"localization/#making-a-localization-plot","text":"Example hdr = f [ 'projection' ] . attrs CL = f [ 'projection/data' ][:] extent = np . array ([ - hdr [ 'xsize' ] / 2 , hdr [ 'xsize' ] / 2 , - hdr [ 'ysize' ] / 2 , hdr [ 'ysize' ] / 2 ]) * hdr [ 'reso' ] / 60 plt . rc ( 'font' , family = 'serif' , size = 14 ) plt . figure ( figsize = ( 10 , 4 )) # Note: RA increases to the left! im = plt . imshow ( CL , vmin = 0 , origin = 'lower' , extent = extent , cmap = 'magma' ) plt . contour ( CL , levels = [ 0.68 , 0.95 ], linestyles = [ '-' , '--' ], colors = 'k' , linewidths = 2 , extent = extent ) plt . colorbar ( im , pad = 0.25 , shrink = 0.4 , orientation = 'horizontal' , label = 'Confidence Level' ) plt . arrow ( 2.4 , - 0.4 , 0 , 0.2 , head_width = 0.04 , color = 'k' ) plt . text ( 2.39 , - 0.1 , 'N' , ha = 'center' , size = 10 ) plt . arrow ( 2.4 , - 0.4 , - 0.2 , 0. , head_width = 0.04 , color = 'k' ) plt . text ( 2.1 , - 0.4 , 'E' , va = 'center' , ha = 'right' , size = 10 ) plt . title ( 'Centered @ %.3f , %.2f ' % ( hdr [ 'clon' ], hdr [ 'clat' ])) plt . xlabel ( 'dx (deg)' ) plt . ylabel ( 'dy (deg)' ) Your plot generated from the above script should look similar to this plot:","title":"Making a Localization Plot"},{"location":"localization/#contours","text":"Example describe(f['/contours'], recurse=True) Hint The above example's output should look like the following: /contours attrs: { comments: (R.A., Dec.) contours of common confidence intervals. Islands (labelled ABC...) are ordered with increasing R.A. Contours are extracted from the Gnomonic projection, and have been simplified using the Ramer-Douglas-Peucker algorithm (with an epsilon parameter of 0.2 pixels). } ------------------------------------------------------------ /contours/50 A: (2, 22) float32 B: (2, 30) float32 C: (2, 38) float32 ------------------------------------------------------------ /contours/68 A: (2, 24) float32 B: (2, 28) float32 C: (2, 34) float32 D: (2, 43) float32 ------------------------------------------------------------ /contours/90 A: (2, 34) float32 B: (2, 51) float32 C: (2, 46) float32 ------------------------------------------------------------ /contours/95 A: (2, 41) float32 B: (2, 54) float32 C: (2, 48) float32","title":"Contours"},{"location":"localization/#making-a-contour-plot","text":"Example # example 0: getting points ra , dec = f [ 'contours/68/A' ] # example 2: plotting contours plt . figure ( figsize = ( 10 , 2 )) for name , contour in f [ 'contours/68' ] . items (): contour = contour [:] plt . plot ( * contour ) plt . plot ( * contour . mean ( 1 ), 'wo' , mec = 'k' , ms = 20 , alpha = 0.5 ) plt . text ( * contour . mean ( 1 ), s = name , ha = 'center' , va = 'center' ) for contour in f [ 'contours/95' ] . values (): plt . plot ( * contour [:], '--' ) plt . xlim ( * plt . xlim ()[:: - 1 ]) plt . xlabel ( 'R.A. (deg)' ) plt . ylabel ( 'Dec. (deg)' ) Your plot generated from the above script should look similar to this plot:","title":"Making a Contour Plot\u00b6"},{"location":"scientific/","text":"Coming Soon...","title":"Scientific"},{"location":"technical/","text":"Coming Soon...","title":"Technical"},{"location":"waterfall/","text":"CHIME/FRB Waterfall Data \u00b6 Author: Pranav Sanghvi This tutorial will help you get aquainted with the CHIME/FRB Catalog waterfall data. In this tutorial, the data file FRB20180725A_waterfall.h5 was used, which contains data for FRB 20180725A. This data can be downloaded from the CHIME/FRB Open Data Release . To download additional data, visit the Canadian Astronomy Data Center . All of the code provided in this tutorial, is also availaible through the CHIME/FRB Open Data python package. cfod from cfod.routines import waterfaller wfall = Waterfaller ( filename = ` FRB20180725A_waterfall . h5 ` ) wfall . plot ( save = False ) wfall . cal_plot ( save = True ) Read hdf5 files \u00b6 The user can use the file_name variable to store the name of the file that contains the FRB data to be analyzed. Be sure to follow the instructions for downloading the hdf5 file for each FRB as desrcibed above. The file should be placed in the same directory as this notebook, or the full path should be specified in file_name . Example file_name = \"FRB20180725A_waterfall.h5\" data = h5py . File ( file_name , \"r\" ) Explore the data files \u00b6 File Contents list ( data . keys ()) >>> [ 'frb' ] Metadata list ( data [ \"frb\" ] . keys ()) >>> [ 'calibrated_wfall' , 'extent' , 'model_spec' , 'model_ts' , 'model_wfall' , 'plot_freq' , 'plot_time' , 'spec' , 'ts' , 'wfall' ] Metadata Description extent : the extent of the waterfall data plot_freq : The values of the frequecy indices in \\(\\rm{MHz}\\) plot_time : The value of the time indices in \\(\\rm{\\mu s}\\) wfall : waterfall data model_wfall : waterfall from fitted data spec : Dynamic Spectrum model_spec : model-fitted dynamic spectrum ts : time series data model_ts : model-fitted time series caliberated_wfall : The waterfall data with calibration applied Unpack the Data data = data [ \"frb\" ] eventname = data . attrs [ \"tns_name\" ] . decode () wfall = data [ \"wfall\" ][:] model_wfall = data [ \"model_wfall\" ][:] plot_time = data [ \"plot_time\" ][:] plot_freq = data [ \"plot_freq\" ][:] ts = data [ \"ts\" ][:] model_ts = data [ \"model_ts\" ][:] spec = data [ \"spec\" ][:] model_spec = data [ \"model_spec\" ][:] extent = data [ \"extent\" ][:] dm = data . attrs [ \"dm\" ][()] scatterfit = data . attrs [ \"scatterfit\" ][()] cal_obs_date = data . attrs [ \"calibration_observation_date\" ] . decode () cal_source_name = data . attrs [ \"calibration_source_name\" ] . decode () cal_wfall = data [ \"calibrated_wfall\" ][:] dt = np . median ( np . diff ( plot_time )) # the delta (time) between time bins # this value is the same for both caliberated and uncalibrated data Removing the Radio Frequency Interference \u00b6 This process sets any frequency channel that has a higher variance than the mean variance (averaged across all frequency channels) to a NaN value using np.nan . RFI Removal q1 = np . nanquantile ( spec , 0.25 ) q3 = np . nanquantile ( spec , 0.75 ) iqr = q3 - q1 # additional masking of channels with RFI rfi_masking_var_factor = 3 channel_variance = np . nanvar ( wfall , axis = 1 ) mean_channel_variance = np . nanmean ( channel_variance ) with np . errstate ( invalid = \"ignore\" ): rfi_mask = ( channel_variance > \\ rfi_masking_var_factor * mean_channel_variance ) \\ | ( spec [:: - 1 ] < q1 - 1.5 * iqr ) | ( spec [:: - 1 ] > q3 + 1.5 * iqr ) wfall [ rfi_mask , ... ] = np . nan model_wfall [ rfi_mask , ... ] = np . nan spec [ rfi_mask [:: - 1 ]] = np . nan # remake time-series after RFI masking ts = np . nansum ( wfall , axis = 0 ) model_ts = np . nansum ( model_wfall , axis = 0 ) Determine the Peaks and SNR of the Pulse \u00b6 Peaks are identified after boxcar convolution. Pulse Properties def boxcar_kernel ( width ): width = int ( round ( width , 0 )) return np . ones ( width , dtype = \"float32\" ) / np . sqrt ( width ) def find_burst ( ts , min_width = 1 , max_width = 128 ): min_width = int ( min_width ) max_width = int ( max_width ) # do not search widths bigger than timeseries widths = list ( range ( min_width , min ( max_width + 1 , len ( ts ) - 2 ))) # envelope finding snrs = np . empty_like ( widths , dtype = float ) peaks = np . empty_like ( widths , dtype = int ) for i in range ( len ( widths )): convolved = scipy . signal . convolve ( ts , boxcar_kernel ( widths [ i ]), mode = \"same\" ) peaks [ i ] = np . nanargmax ( convolved ) snrs [ i ] = convolved [ peaks [ i ]] best_idx = np . nanargmax ( snrs ) return peaks [ best_idx ], widths [ best_idx ], snrs [ best_idx ] peak, width, snr = find_burst(ts) print(f\"Peak: {peak} at time sample, Width = {width*dt} ms, SNR = {snr}\") Visualize the Dynamic Spectra \u00b6 First and foremost, we need to bin the frequency data before we visualize it. Bin Frequency Data def bin_freq_channels ( data , fbin_factor = 4 ): num_chan = data . shape [ 0 ] if num_chan % fbin_factor != 0 : raise ValueError ( \"frequency binning factor `fbin_factor` should be even\" ) data = np . nanmean ( data . reshape (( num_chan // fbin_factor , fbin_factor ) + data . shape [ 1 :]), axis = 1 ) return data # bin frequency channels such that we have 16,384/16 = 1024 frequency channels wfall = bin_freq_channels ( wfall , 16 ) Plot the Dynamic Spectrum fig = plt . figure ( figsize = ( 6 , 6 )) ## Set up the image grid gs = gridspec . GridSpec ( ncols = 2 , nrows = 2 , figure = fig , width_ratios = [ 3 , 1 ], height_ratios = [ 1 , 3 ], hspace = 0.0 , wspace = 0.0 ) data_im = plt . subplot ( gs [ 2 ]) data_ts = plt . subplot ( gs [ 0 ], sharex = data_im ) data_spec = plt . subplot ( gs [ 3 ], sharey = data_im ) ### time stamps relative to the peak peak_idx = np . argmax ( ts ) extent [ 0 ] = extent [ 0 ] - plot_time [ peak_idx ] extent [ 1 ] = extent [ 1 ] - plot_time [ peak_idx ] plot_time -= plot_time [ peak_idx ] # prepare time-series for histogramming plot_time -= dt / 2. plot_time = np . append ( plot_time , plot_time [ - 1 ] + dt ) cmap = plt . cm . viridis ### plot dynamic spectrum wfall [ np . isnan ( wfall )] = np . nanmedian ( wfall ) # replace nans in the data with the data median # use standard deviation of residuals to set color scale vmin = np . nanpercentile ( wfall , 1 ) vmax = np . nanpercentile ( wfall , 99 ) data_im . imshow ( wfall , aspect = \"auto\" , interpolation = \"none\" , extent = extent , vmin = vmin , vmax = vmax , cmap = cmap ) ### plot time-series data_ts . plot ( plot_time , np . append ( ts , ts [ - 1 ]), color = \"tab:gray\" , drawstyle = \"steps-post\" ) ### plot spectrum data_spec . plot ( spec , plot_freq , color = \"tab:gray\" ) ### plot model time-series and spectrum if scatterfit : data_spec . plot ( model_spec , plot_freq , color = cmap ( 0.25 )) data_ts . plot ( plot_time , np . append ( model_ts , model_ts [ - 1 ]), color = cmap ( 0.25 ), drawstyle = \"steps-post\" , lw = 2 ) else : data_spec . plot ( model_spec , plot_freq , color = cmap ( 0.5 )) data_ts . plot ( plot_time , np . append ( model_ts , model_ts [ - 1 ]), color = cmap ( 0.5 ), drawstyle = \"steps-post\" , lw = 1 ) ## BEautify plot # remove some labels and ticks for neatness plt . setp ( data_ts . get_xticklabels (), visible = False ) data_ts . set_yticklabels ([], visible = True ) data_ts . set_yticks ([]) data_ts . set_xlim ( extent [ 0 ], extent [ 1 ]) plt . setp ( data_spec . get_yticklabels (), visible = False ) data_spec . set_xticklabels ([], visible = True ) data_spec . set_xticks ([]) data_spec . set_ylim ( extent [ 2 ], extent [ 3 ]) plt . setp ( data_im . get_xticklabels (), fontsize = 9 ) plt . setp ( data_im . get_yticklabels (), fontsize = 9 ) #### highlighting the width of the pulse data_ts . axvspan ( max ( plot_time . min (), plot_time [ peak ] + 0.5 * dt \\ - ( 0.5 * width ) * dt ), min ( plot_time . max (), plot_time [ peak ] + 0.5 * dt \\ + ( 0.5 * width ) * dt ), facecolor = \"tab:blue\" , edgecolor = None , alpha = 0.1 ) ##### add event ID and DM labels xlim = data_ts . get_xlim () ylim = data_ts . get_ylim () # add 20% extra white space at the top span = np . abs ( ylim [ 1 ]) + np . abs ( ylim [ 0 ]) data_ts . set_ylim ( ylim [ 0 ], ylim [ 1 ] + 0.2 * span ) ylim = data_ts . get_ylim () ypos = ( ylim [ 1 ] - ylim [ 0 ]) * 0.9 + ylim [ 0 ] xpos = ( xlim [ 1 ] - xlim [ 0 ]) * 0.98 + extent [ 0 ] data_ts . text ( xpos , ypos , \" {} \\n DM: {:.1f} pc/cc \\n SNR: {:.2f} \" . format ( eventname , dm , snr ), ha = \"right\" , va = \"top\" , fontsize = 9 ) data_im . locator_params ( axis = \"x\" , min_n_ticks = 3 ) data_im . set_yticks ([ 400 , 500 , 600 , 700 , 800 ]) data_im . set_ylabel ( \"Frequency [MHz]\" , fontsize = 9 ) data_im . set_xlabel ( \"Time [ms]\" , fontsize = 9 ) #savefigure plt . savefig ( \" {} _wfall.png\" . format ( eventname ), dpi = 300 , bbox_inches = \"tight\" ) Plotting Calibrated Data \u00b6 Within the hdf5 file is the calibrated waterfall data, allowing one to plot the data as measured in Janskys. Extract the Waterfall and Construct the Time Series cal_ts = np . nanmean ( cal_wfall , axis = 0 ) cal_wfall [ np . isnan ( cal_wfall )] = np . nanmedian ( cal_wfall ) # replace nans in the data with the data median #bin frequency channels such that we have 16,384/16 = 1024 frequency channels cal_wfall = bin_freq_channels ( cal_wfall , 16 ) vmin = np . nanpercentile ( cal_wfall , 1 ) vmax = np . nanpercentile ( cal_wfall , 99 ) times = np . arange ( len ( cal_ts )) * dt peak_idx = np . argmax ( cal_ts ) times -= times [ peak_idx ] times -= dt / 2. extent [ 0 ] = times [ 0 ] extent [ 1 ] = times [ - 1 ] fig = plt . figure ( figsize = ( 5 , 5 ), constrained_layout = True ) layout = \"\"\" A C \"\"\" ax_dict = fig . subplot_mosaic ( layout ) ax_dict [ \"A\" ] . imshow ( cal_wfall , aspect = \"auto\" , vmin = vmin , vmax = vmax , extent = extent ) ax_dict [ \"A\" ] . set_title ( f \"Waterfall of { eventname } \\n Calibrated to { cal_source_name } on { cal_obs_date } \" ) ax_dict [ \"A\" ] . set_yticks ([ 400 , 500 , 600 , 700 , 800 ]) ax_dict [ \"C\" ] . plot ( times , cal_ts , drawstyle = \"steps-post\" ) ax_dict [ \"C\" ] . set_xlabel ( \"Time [ms]\" ) ax_dict [ \"C\" ] . set_title ( f \"Time Series of { eventname } \\n Calibrated to { cal_source_name } on { cal_obs_date } \\ \\n Peak flux = { cal_ts [ peak_idx ] : .3f } Jy\" ) ax_dict [ \"A\" ] . set_ylabel ( \"Frequency [MHz]\" ) ax_dict [ \"C\" ] . set_ylabel ( \"Flux [Jy]\" )","title":"Make a Waterfall Plot"},{"location":"waterfall/#chimefrb-waterfall-data","text":"Author: Pranav Sanghvi This tutorial will help you get aquainted with the CHIME/FRB Catalog waterfall data. In this tutorial, the data file FRB20180725A_waterfall.h5 was used, which contains data for FRB 20180725A. This data can be downloaded from the CHIME/FRB Open Data Release . To download additional data, visit the Canadian Astronomy Data Center . All of the code provided in this tutorial, is also availaible through the CHIME/FRB Open Data python package. cfod from cfod.routines import waterfaller wfall = Waterfaller ( filename = ` FRB20180725A_waterfall . h5 ` ) wfall . plot ( save = False ) wfall . cal_plot ( save = True )","title":"CHIME/FRB Waterfall Data"},{"location":"waterfall/#read-hdf5-files","text":"The user can use the file_name variable to store the name of the file that contains the FRB data to be analyzed. Be sure to follow the instructions for downloading the hdf5 file for each FRB as desrcibed above. The file should be placed in the same directory as this notebook, or the full path should be specified in file_name . Example file_name = \"FRB20180725A_waterfall.h5\" data = h5py . File ( file_name , \"r\" )","title":"Read hdf5 files"},{"location":"waterfall/#explore-the-data-files","text":"File Contents list ( data . keys ()) >>> [ 'frb' ] Metadata list ( data [ \"frb\" ] . keys ()) >>> [ 'calibrated_wfall' , 'extent' , 'model_spec' , 'model_ts' , 'model_wfall' , 'plot_freq' , 'plot_time' , 'spec' , 'ts' , 'wfall' ] Metadata Description extent : the extent of the waterfall data plot_freq : The values of the frequecy indices in \\(\\rm{MHz}\\) plot_time : The value of the time indices in \\(\\rm{\\mu s}\\) wfall : waterfall data model_wfall : waterfall from fitted data spec : Dynamic Spectrum model_spec : model-fitted dynamic spectrum ts : time series data model_ts : model-fitted time series caliberated_wfall : The waterfall data with calibration applied Unpack the Data data = data [ \"frb\" ] eventname = data . attrs [ \"tns_name\" ] . decode () wfall = data [ \"wfall\" ][:] model_wfall = data [ \"model_wfall\" ][:] plot_time = data [ \"plot_time\" ][:] plot_freq = data [ \"plot_freq\" ][:] ts = data [ \"ts\" ][:] model_ts = data [ \"model_ts\" ][:] spec = data [ \"spec\" ][:] model_spec = data [ \"model_spec\" ][:] extent = data [ \"extent\" ][:] dm = data . attrs [ \"dm\" ][()] scatterfit = data . attrs [ \"scatterfit\" ][()] cal_obs_date = data . attrs [ \"calibration_observation_date\" ] . decode () cal_source_name = data . attrs [ \"calibration_source_name\" ] . decode () cal_wfall = data [ \"calibrated_wfall\" ][:] dt = np . median ( np . diff ( plot_time )) # the delta (time) between time bins # this value is the same for both caliberated and uncalibrated data","title":"Explore the data files"},{"location":"waterfall/#removing-the-radio-frequency-interference","text":"This process sets any frequency channel that has a higher variance than the mean variance (averaged across all frequency channels) to a NaN value using np.nan . RFI Removal q1 = np . nanquantile ( spec , 0.25 ) q3 = np . nanquantile ( spec , 0.75 ) iqr = q3 - q1 # additional masking of channels with RFI rfi_masking_var_factor = 3 channel_variance = np . nanvar ( wfall , axis = 1 ) mean_channel_variance = np . nanmean ( channel_variance ) with np . errstate ( invalid = \"ignore\" ): rfi_mask = ( channel_variance > \\ rfi_masking_var_factor * mean_channel_variance ) \\ | ( spec [:: - 1 ] < q1 - 1.5 * iqr ) | ( spec [:: - 1 ] > q3 + 1.5 * iqr ) wfall [ rfi_mask , ... ] = np . nan model_wfall [ rfi_mask , ... ] = np . nan spec [ rfi_mask [:: - 1 ]] = np . nan # remake time-series after RFI masking ts = np . nansum ( wfall , axis = 0 ) model_ts = np . nansum ( model_wfall , axis = 0 )","title":"Removing the Radio Frequency Interference"},{"location":"waterfall/#determine-the-peaks-and-snr-of-the-pulse","text":"Peaks are identified after boxcar convolution. Pulse Properties def boxcar_kernel ( width ): width = int ( round ( width , 0 )) return np . ones ( width , dtype = \"float32\" ) / np . sqrt ( width ) def find_burst ( ts , min_width = 1 , max_width = 128 ): min_width = int ( min_width ) max_width = int ( max_width ) # do not search widths bigger than timeseries widths = list ( range ( min_width , min ( max_width + 1 , len ( ts ) - 2 ))) # envelope finding snrs = np . empty_like ( widths , dtype = float ) peaks = np . empty_like ( widths , dtype = int ) for i in range ( len ( widths )): convolved = scipy . signal . convolve ( ts , boxcar_kernel ( widths [ i ]), mode = \"same\" ) peaks [ i ] = np . nanargmax ( convolved ) snrs [ i ] = convolved [ peaks [ i ]] best_idx = np . nanargmax ( snrs ) return peaks [ best_idx ], widths [ best_idx ], snrs [ best_idx ] peak, width, snr = find_burst(ts) print(f\"Peak: {peak} at time sample, Width = {width*dt} ms, SNR = {snr}\")","title":"Determine the Peaks and SNR of the Pulse"},{"location":"waterfall/#visualize-the-dynamic-spectra","text":"First and foremost, we need to bin the frequency data before we visualize it. Bin Frequency Data def bin_freq_channels ( data , fbin_factor = 4 ): num_chan = data . shape [ 0 ] if num_chan % fbin_factor != 0 : raise ValueError ( \"frequency binning factor `fbin_factor` should be even\" ) data = np . nanmean ( data . reshape (( num_chan // fbin_factor , fbin_factor ) + data . shape [ 1 :]), axis = 1 ) return data # bin frequency channels such that we have 16,384/16 = 1024 frequency channels wfall = bin_freq_channels ( wfall , 16 ) Plot the Dynamic Spectrum fig = plt . figure ( figsize = ( 6 , 6 )) ## Set up the image grid gs = gridspec . GridSpec ( ncols = 2 , nrows = 2 , figure = fig , width_ratios = [ 3 , 1 ], height_ratios = [ 1 , 3 ], hspace = 0.0 , wspace = 0.0 ) data_im = plt . subplot ( gs [ 2 ]) data_ts = plt . subplot ( gs [ 0 ], sharex = data_im ) data_spec = plt . subplot ( gs [ 3 ], sharey = data_im ) ### time stamps relative to the peak peak_idx = np . argmax ( ts ) extent [ 0 ] = extent [ 0 ] - plot_time [ peak_idx ] extent [ 1 ] = extent [ 1 ] - plot_time [ peak_idx ] plot_time -= plot_time [ peak_idx ] # prepare time-series for histogramming plot_time -= dt / 2. plot_time = np . append ( plot_time , plot_time [ - 1 ] + dt ) cmap = plt . cm . viridis ### plot dynamic spectrum wfall [ np . isnan ( wfall )] = np . nanmedian ( wfall ) # replace nans in the data with the data median # use standard deviation of residuals to set color scale vmin = np . nanpercentile ( wfall , 1 ) vmax = np . nanpercentile ( wfall , 99 ) data_im . imshow ( wfall , aspect = \"auto\" , interpolation = \"none\" , extent = extent , vmin = vmin , vmax = vmax , cmap = cmap ) ### plot time-series data_ts . plot ( plot_time , np . append ( ts , ts [ - 1 ]), color = \"tab:gray\" , drawstyle = \"steps-post\" ) ### plot spectrum data_spec . plot ( spec , plot_freq , color = \"tab:gray\" ) ### plot model time-series and spectrum if scatterfit : data_spec . plot ( model_spec , plot_freq , color = cmap ( 0.25 )) data_ts . plot ( plot_time , np . append ( model_ts , model_ts [ - 1 ]), color = cmap ( 0.25 ), drawstyle = \"steps-post\" , lw = 2 ) else : data_spec . plot ( model_spec , plot_freq , color = cmap ( 0.5 )) data_ts . plot ( plot_time , np . append ( model_ts , model_ts [ - 1 ]), color = cmap ( 0.5 ), drawstyle = \"steps-post\" , lw = 1 ) ## BEautify plot # remove some labels and ticks for neatness plt . setp ( data_ts . get_xticklabels (), visible = False ) data_ts . set_yticklabels ([], visible = True ) data_ts . set_yticks ([]) data_ts . set_xlim ( extent [ 0 ], extent [ 1 ]) plt . setp ( data_spec . get_yticklabels (), visible = False ) data_spec . set_xticklabels ([], visible = True ) data_spec . set_xticks ([]) data_spec . set_ylim ( extent [ 2 ], extent [ 3 ]) plt . setp ( data_im . get_xticklabels (), fontsize = 9 ) plt . setp ( data_im . get_yticklabels (), fontsize = 9 ) #### highlighting the width of the pulse data_ts . axvspan ( max ( plot_time . min (), plot_time [ peak ] + 0.5 * dt \\ - ( 0.5 * width ) * dt ), min ( plot_time . max (), plot_time [ peak ] + 0.5 * dt \\ + ( 0.5 * width ) * dt ), facecolor = \"tab:blue\" , edgecolor = None , alpha = 0.1 ) ##### add event ID and DM labels xlim = data_ts . get_xlim () ylim = data_ts . get_ylim () # add 20% extra white space at the top span = np . abs ( ylim [ 1 ]) + np . abs ( ylim [ 0 ]) data_ts . set_ylim ( ylim [ 0 ], ylim [ 1 ] + 0.2 * span ) ylim = data_ts . get_ylim () ypos = ( ylim [ 1 ] - ylim [ 0 ]) * 0.9 + ylim [ 0 ] xpos = ( xlim [ 1 ] - xlim [ 0 ]) * 0.98 + extent [ 0 ] data_ts . text ( xpos , ypos , \" {} \\n DM: {:.1f} pc/cc \\n SNR: {:.2f} \" . format ( eventname , dm , snr ), ha = \"right\" , va = \"top\" , fontsize = 9 ) data_im . locator_params ( axis = \"x\" , min_n_ticks = 3 ) data_im . set_yticks ([ 400 , 500 , 600 , 700 , 800 ]) data_im . set_ylabel ( \"Frequency [MHz]\" , fontsize = 9 ) data_im . set_xlabel ( \"Time [ms]\" , fontsize = 9 ) #savefigure plt . savefig ( \" {} _wfall.png\" . format ( eventname ), dpi = 300 , bbox_inches = \"tight\" )","title":"Visualize the Dynamic Spectra"},{"location":"waterfall/#plotting-calibrated-data","text":"Within the hdf5 file is the calibrated waterfall data, allowing one to plot the data as measured in Janskys. Extract the Waterfall and Construct the Time Series cal_ts = np . nanmean ( cal_wfall , axis = 0 ) cal_wfall [ np . isnan ( cal_wfall )] = np . nanmedian ( cal_wfall ) # replace nans in the data with the data median #bin frequency channels such that we have 16,384/16 = 1024 frequency channels cal_wfall = bin_freq_channels ( cal_wfall , 16 ) vmin = np . nanpercentile ( cal_wfall , 1 ) vmax = np . nanpercentile ( cal_wfall , 99 ) times = np . arange ( len ( cal_ts )) * dt peak_idx = np . argmax ( cal_ts ) times -= times [ peak_idx ] times -= dt / 2. extent [ 0 ] = times [ 0 ] extent [ 1 ] = times [ - 1 ] fig = plt . figure ( figsize = ( 5 , 5 ), constrained_layout = True ) layout = \"\"\" A C \"\"\" ax_dict = fig . subplot_mosaic ( layout ) ax_dict [ \"A\" ] . imshow ( cal_wfall , aspect = \"auto\" , vmin = vmin , vmax = vmax , extent = extent ) ax_dict [ \"A\" ] . set_title ( f \"Waterfall of { eventname } \\n Calibrated to { cal_source_name } on { cal_obs_date } \" ) ax_dict [ \"A\" ] . set_yticks ([ 400 , 500 , 600 , 700 , 800 ]) ax_dict [ \"C\" ] . plot ( times , cal_ts , drawstyle = \"steps-post\" ) ax_dict [ \"C\" ] . set_xlabel ( \"Time [ms]\" ) ax_dict [ \"C\" ] . set_title ( f \"Time Series of { eventname } \\n Calibrated to { cal_source_name } on { cal_obs_date } \\ \\n Peak flux = { cal_ts [ peak_idx ] : .3f } Jy\" ) ax_dict [ \"A\" ] . set_ylabel ( \"Frequency [MHz]\" ) ax_dict [ \"C\" ] . set_ylabel ( \"Flux [Jy]\" )","title":"Plotting Calibrated Data"}]}